{
  "filename": "Coevolution_Based_Adaptive_Monte_Carlo_Localizatio.pdf",
  "text_length": 41529,
  "chunk_count": 17,
  "chunks": [
    "_Ronghua, L & Bingrong, H / Coevolution Based Adaptive Monte Carlo Localization (CEAMCL), pp 183 - 190,_\n_International Journal of Advanced Robotic Systems, Volume 1, Number 3 (2004), ISSN 1729-8806_\n\n## **Coevolution Based Adaptive Monte Carlo Localization (CEAMCL)**\n\n\n**Luo Ronghua & Hong Bingrong**\nDepartment of Computer Science, Harbin Institute of Technology, Harbin 150001, P 183 - 190,_\n_International Journal of Advanced Robotic Systems, Volume 1, Number 3 (2004), ISSN 1729-8806_\n\n## **Coevolution Based Adaptive Monte Carlo Localization (CEAMCL)**\n\n\n**Luo Ronghua & Hong Bingrong**\nDepartment of Computer Science, Harbin Institute of Technology, Harbin 150001, P R China,\nronghua75@yahoo com cn\n\n\n_**Abstract:**_ _An adaptive Monte Carlo localization algorithm based on coevolution mechanism of ecological species is_\n_proposed Samples are clustered into species, each of which represents a hypothesis of the robot’s pose Since the_\n_coevolution between the species ensures that the multiple distinct hypotheses can be tracked stably, the_ _problem of_\n_premature convergence_ _when using MCL in highly symmetric environments can be solved And the sample size can be_\n_adjusted adaptively over time according to the uncertainty of the robot’s pose by using the population growth model In_\n_addition, by using the crossover and mutation operators in evolutionary computation, intra-species evolution can drive_\n_the samples move towards the regions where the desired posterior density is large So a small size of samples can_\n_represent the desired density well enough to make precise localization The new algorithm is termed coevolution based_\n_adaptive Monte Carlo localization (CEAMCL) Experiments have been carried out to prove the efficiency of the new_\n_localization algorithm _\n_**Keywords:**_ _Monte Carlo localization, coevolution, evolutionary computation, robot localization_\n\n\n\n**1 Introduction**\n\nSelf-localization, a basic problem in mobile robot\nsystems, can be divided into two sub-problems: pose\ntracking and global localization In pose tracking, the\ninitial robot pose is known, and localization seeks to\nidentify small, incremental errors in a robot’s odometry\n(Leonard, J J & Durrant-Whyte, H F , 1991)",
    ", 1991) In global\nlocalization, however the robot is required to estimate its\npose by local and incomplete observed information\nunder the condition of uncertain initial pose Global\nlocalization is a more challenging problem Only most\nrecently, several approaches based on probabilistic\ntheory are proposed for global localization, including\ngrid-based approaches (Burgard, W _et al_, 1996),\ntopological approaches (Kaelbling, L P _et al_, 1996)\n(Simmons, R & Koenig, S , 1995), Monte Carlo\nlocalization (Dellaert, F _et al,_ 1999) and multihypothesis tracking (Jensfelt, P & Kristensen, S , 2001)\n(Roumeliotis, S I & Bekey, G A , 2000) By\nrepresenting probability densities with sets of samples\nand using the sequential Monte Carlo importance\nsampling (Andrieu, C & Doucet, A & Doucet, A , 2002), Monte\nCarlo localization (MCL) can represent non-linear and\nnon-Gaussian models well and focus the computational\nresources on regions with high likelihood So MCL has\nattracted wide attention and has been applied in many\nreal robot systems But traditional MCL has some\nshortcomings Since samples are actually drawn from a\n\n\n\nproposal density, if the observation density moves into\none of the tails of the proposal density, most of the\nsamples’ non-normalized importance factors will be\nsmall In this case, a large sample size is needed to\nrepresent the true posterior density to ensure stable and\nprecise localization Another problem is that samples\noften too quickly converge to a single, high likelihood\npose This might be undesirable in the case of\nlocalization in symmetric environments, where multiple\ndistinct hypotheses have to be tracked for extended\nperiods of time How to get higher localization precision,\nto improve efficiency and to prevent premature\nconvergence of MCL are the key concerns of the\nresearchers To make the samples represent the posterior\ndensity better, Thrun et al proposed mixture-MCL\n(Thrun, S _et al,_ 2001), but it needs much additional\ncomputation in the sampling process To improve the\nefficiency of MCL, methods adjusting sample size\nadaptively over time are proposed (Fox, D , 2003)\n(Koller, D & Fratkina, R , 1998), but they increase the\nprobability of premature convergence Although\nclustered particle filters are applied to solve premature\nconvergence (Milstein, A _et al_, 2002), the method loses\nthe advantage of focusing the computational resources\non regions with high likelihood because it maintains the\nsame sample size for all clusters In this paper, a new version of MCL is proposed to\novercome those limitations",
    "In this paper, a new version of MCL is proposed to\novercome those limitations Samples are clustered into\ngroups which are also called species A coevolutionary\n\n\n183\n\n\nmodel derived from competition of ecological species is\nintroduced to make the species evolve cooperatively, so\nthe premature convergence in highly symmetric\nenvironment can be prevented The population growth\nmodel of species enables the sample size to be adjusted\naccording to the total environment resources which\nrepresent uncertainty of the pose of the robot And\ngenetic operators are used for intra-species evolution to\nsearch for optimal samples in each species So the\nsamples can represent the desired posterior density\nbetter, and precise localization can be realized with a\nsmall size of sample Compared with the traditional\nMCL, the new algorithm has the following advantages:\n(1) it can adaptively adjust the sample size during\nlocalization; (2) it can make stable localization in highly\nsymmetric environment; (3) it can make precise\nlocalization with a small sample size Compared with the traditional\nMCL, the new algorithm has the following advantages:\n(1) it can adaptively adjust the sample size during\nlocalization; (2) it can make stable localization in highly\nsymmetric environment; (3) it can make precise\nlocalization with a small sample size **2 Background**\n\n_2 1 1 Robot Localization Problem_\n\nRobot localization is to estimate the current state _[x]_ _t_ [of ]\n\n\nthe robot, given the information about initial state and all\n\nthe measurements _Y_ up to current time: _t_\n\n_Y_ _t_ = { _y_ _t_ | _t_ =,1,0 �, _t_ } (1)\n\n\nTypically, the state _[x]_ _t_ [ is a three-dimensional vector ]\n\n\nincluding the position and direction of the robot, i",
    "Robot Localization Problem_\n\nRobot localization is to estimate the current state _[x]_ _t_ [of ]\n\n\nthe robot, given the information about initial state and all\n\nthe measurements _Y_ up to current time: _t_\n\n_Y_ _t_ = { _y_ _t_ | _t_ =,1,0 �, _t_ } (1)\n\n\nTypically, the state _[x]_ _t_ [ is a three-dimensional vector ]\n\n\nincluding the position and direction of the robot, i e the\npose of the robot From a statistical point of view, the\n\nestimation of _[x]_ _t_ [is an instance of Bayes filtering ]\n\n\nproblem, which can be implemented by constructing the\n\n\n_t_\nposterior density _p_ ( _x_ _t_ | _[Y]_ ) Assuming the\n\n\nenvironment is a Markov process, Bayes filters\n\nenable _p_ ( _x_ _t_ | _[Y]_ _t_ ) to be computed recursively in two\n\n\nsteps Prediction step: Predicting the state of the next\n\ntime-step with previous state _[x]_ _t_ − 1 according to the\n\n\nmotion model _p_ ( _x_ _t_ | _x_ _t_ − 1, _u_ _t_ − 1 ) :\n\n_p_ ( _x_ _t_ | _Y_ _t_ − 1 ) _t_ − 1\n\n\n_t_ − 1\n= _p_ ( _x_ _t_ | _x_ _t_ − 1, _u_ _t_ − 1 ) _p_ ( _x_ _t_ − 1 | _Y_ ) _dx_ (2)\n# ∫\n\n\nUpdate step: Updating the state with the newly observed\n\ninformation _[y]_ [ according to the perceptual model ] _t_\n\n_p_ ( _y_ _t_ | _x_ _t_ ) :\n\n\n\n1\n\n\n\n_t_ _p_ ( _y_ _t_ | _x_ _t_ ) _p_ ( _x_ _t_ | _Y_ _t_ − 1 )\n_p_ ( _x_ _t_ | _Y_ ) = _p_ ( _y_ _t_ | _Y_ _t_ − 1 ) (3)\n\n\n\n_t_\nposterior density _p_ ( _x_ _t_ | _[Y]_ ) by a set of weighted\n\n\nsamples _[S]_ [ : ] _t_\n\n_S_ _t_ = {( _x_ _t_ ( _j_ ), _w_ _t_ ( _j_ ) |) _j_ =,1 �, _N_ } (4)\n\nWhere _[x]_ _t_ ( _j_ ) is a possible state of the robot at current\n\n\n( _j_ )\ntime _t_ The non-negative numerical factor _w_ _t_ called\n\n\nimportance factor represents the probability that the state\n\n( _j_ )\nof robot is _[x]_ _t_ at time _t_ MCL includes the following\n\n\nthree steps:\n(1) Resampling: Resample _N_ samples randomly from\n\n_[S]_ _t_ − 1, according to the distribution defined by _w_ _t_ − 1 ;\n\n\n( _j_ )\n(2) Importance sampling: sample state _[x]_ _t_ from\n\n_p_ ( _x_ _t_ | _x_ _t_ ( − _j_ 1), _u_ _t_ − 1 ) for each of the _N_ possible state\n\n_[x]_ _t_ ( − _j_ 1) [; ] and evaluate the importance\n\nfactor _w_ _t_ ( _j_ ) = _p_ ( _y_ _t_ | _x_ _t_ ( _j_ ) ) (3) Summary: normalize the importance factors\n# w t ( j ) = w t ( j ) / ∑ kN = 1 w t ( k ) ; and calculate the\n\n\nstatistic property of sample set _[S]_ [ to estimate the ] _t_\n\n\npose of the robot _2 3",
    "3 _ _Coevolutionary algorithms_\nEvolutionary algorithms (EAs), especially genetic\nalgorithms, have been successfully used in different\nmobile robot applications, such as path planning (Chen,\nM & Zalzala, A , 1995) (Potvin, J _et al_, 1996), map\nbuilding (Duckett, T , 2003) and even pose tracking for\nrobot localization (Moreno, L _et al_, 2002) But\npremature convergence is one of the main limitations\nwhen using evolutionary computation algorithms in\nmore complex applications as in the case of global\nlocalization Coevolutionary algorithms (CEAs) are extensions of\nEAs Based on the interaction between species,\ncoevolution mechanism in CEAs can preserve diversity\nwithin the population of evolutionary algorithms to\nprevent premature convergence According to the\ncharacters of interaction between species, CEAs can be\ndivided into cooperative coevolutionary algorithms and\ncompetitive coevolutionary algorithms Cooperative\n(also called symbiotic) coevolutionary algorithms\ninvolve a number of independently evolving species\nwhich together form complex structures The fitness of\nan individual depends on its ability to collaborate with\nindividuals from other species Individuals are rewarded\nwhen they work well with other individuals and\npunished when they perform poorly together (Moriarty,\nD E & Miikkulainen, R , 1997) (Potter, M A & De\nJong, K A , 2000) , 2000) In competitive coevolutionary\nalgorithms, however the increased fitness of one of the\nspecies implies a diminution in the fitness of the other\nspecies This evolutionary pressure tends to produce new\nstrategies in the populations involved so as to maintain\n\n\n\n_t_ _p_ ( _y_ _t_ | _x_ _t_ ) _p_ ( _x_ _t_ | _Y_ − )\n\n( _x_ _t_ | _Y_ ) = _p_ ( _y_ _t_ | _Y_ _t_ − 1 )\n\n\n\n_p_ ( _y_ _t_ | _x_ _t_ ) _p_ ( _x_ _t_ | _Y_ −\n\n=\n\n_p_ ( _y_ _t_ | _Y_ _t_ − 1 )\n\n\n\n−\n\n\n\n_2 2",
    "2 Monte Carlo localization (MCL)_\nIf the state space is continuous, as is the case in mobile\nrobot localization, implementing equations (2) and (3) is\nnot trivial The key idea of MCL is to represent the\n\n\n184\n\n\ntheir chances of survival This “arms race” ideally\nincreases the capabilities of the species until they reach\nan optimum Several methods have been developed to\nencourage the arms race (Angeline, P Several methods have been developed to\nencourage the arms race (Angeline, P J & Pollack, J B ,\n1993) (Ficici, S G & Pollack, J B , 2001) (Rosin, C &\nBelew, R &\nBelew, R , 1997), but these coevolution methods only\nconsider interaction between species and neglect the\neffects of the change of the environment on the species Actually the concept of coevolution is also derived from\necologic science In ecology, much of the early\ntheoretical work on the interaction between species\nstarted with the Lotka-Volterra model of competition\n(Yuchang, S & Xiaoming, C , 1996) The model itself\nwas a modification of the logistic model of the growth of\na single population and represented the result of\ncompetition between species by the change of the\npopulation size of each species Although the model\ncould not embody all the complex relations between\nspecies, it is simple and easy to use So it has been\naccepted by most of the ecologists **3 **3 Coevolution** **Based** **Adaptive** **Monte** **Carlo**\n**Localization**\n\nTo overcome the limitations of MCL, samples are\nclustered into different species Samples in each species\nhave similar characteristics, and each of the species\nrepresents a hypothesis of the place where the robot is\nlocated The Lotka-Volterra model is used to model the\n\ncompetition between species The competition for\nlimited resources will lead to the extinction of some\n\nspecies, and at the same time make some species become\nmore complex so as to coexist with each other The\nenvironment resources which represent uncertainty of\nthe pose of the robot will change over time, so the total\nsample size will also change over time Compared with\nother coevolution models, our model involves the effects\nof competition between species as well as that of the\nchange of environment on species _3 1 Initial Species Generation_\nIn the traditional MCL, the initial samples are randomly\ndrawn from a uniform distribution for global\nlocalization If a small sample size is used, few of the\ninitial samples will fall in the regions where the desired\nposterior density is large, so MCL will fail to localize the\nrobot correctly In this paper, we propose an efficient\ninitial sample selection method, and at the same time the\nmethod will cluster the samples into species In order to select the samples that can represent the\ninitial location of the robot well, a large test sample set\n_S_ _test_ = {(~ _x_ 0(1), _w_ ~ 0(1) ), � (,~ _x_ 0( _N_ _test_ ), _w_ ~ 0( _N_ _test_ ) )} with\n\n\n_N_ _test_ samples is drawn from a uniform distribution over\n\nthe state space, here _w_ ~ 0( _j_ ) = _p_ ( _y_ 0 | ~ _x_ 0( _j_ ) ) Then the\n\n\nmulti-dimensional state space of the robot is partitioned\ninto small hyper-rectangular grids of equal size And\n\nsamples in _S_ _test_ are mapped into the grids The weight\n\n\n\n( _i_ )\nWhere _r_ is the maximum possible rate of population\n\n\ngrowth, _N_ _t_ ( _i_ ) is the population size and _K_ _t_ ( _i_ ) is the\n\n\nupper limit of population size of species _i_ that the\nenvironment resource can support at time step _t_\n\n\n185\n\n\n\nof each grid is the average importance factor of the\nsamples that fall in it A threshold _T_ = µ is used to\n\nclassify the grids into two groups, here the\ncoefficient µ∈ ()1,0 Grids with weight larger than _T_\n\n\nare picked out to form a grid set _V_ The initial sample\n\n\nsize _N_ is defined by: 0\n\n\n_N_ 0 =η | _V_ /| ~~_w_~~ 0 (5)\n\n\nWhere η is a predefined parameter, ~~_w_~~ 0 is the average\n\n\nweight of grids in set _V_, and | _V_ is the number of |\n\n\ngrids in set _V_ This equation means that if the robot\nlocates in a small area with high likelihood, a small\ninitial sample size is needed Using the network defined through neighborhood\nrelations between the grids, the set _V_ is divided into\nconnected regions (i e sets of connected grids) Assuming there are Ω connected regions, these\nconnected regions are used as seeds for the clustering\nprocedure A city-block distance is used in the network\nof grids As in image processing field, the use of distance\nand seeds permits to define influence zones, and the\nboundary between influence zones is known as SKIZ\n(skeleton by influence zone) (Serra, J",
    "As in image processing field, the use of distance\nand seeds permits to define influence zones, and the\nboundary between influence zones is known as SKIZ\n(skeleton by influence zone) (Serra, J , 1982) , 1982) So the\nrobot’s state space is partitioned into Ω parts And\n_N_ 0( _i_ ) samples which have the largest importance factor\n\n\nwill be selected from the test samples falling in the _i_ th\npart Ω\n\n\n# ∑\n\n\n# 0( i ) = N 0 ⋅ w 0 ( i /) ∑ w 0 ( k )\n\n_k_ = 1\n\n\n\n_N_ 0( _i_ ) = _N_ 0 ⋅ _w_ 0 ( _i_ /) _w_ 0 ( _k_ ) (6)\n\n\n\n= 0 ⋅ _w_ 0\n\n=\n\n\n\n_k_\n\n\n\nWhere ~~_w_~~ 0 ( _[k]_ ) is the average weight of grids in the _k_ th\n\npart of the state space The selected _N_ 0( _i_ ) samples from\n\n\n( _i_ )\nthe _i_ th part form an initial species of _N_ 0 population\n\n\nsize _3 2 Inter-Species Competition_\n\nInspired by ecology, when competing with other species\nthe population growth of a species can be modeled using\nthe Lotka-Volterra competition model Assuming there\nare two species, the Lotka-Volterra competition model\nincludes two equations of population growth, one for\neach of two competing species (1) 1() (12) (2)\n\n_t_ 1() 1() _N_ _t_ + α _t_ _N_ _t_\n\n\n\n_dNdt_ _t_ = _r_ 1() _N_ _t_ 1() 1( − _N_ _t_ + _K_ α ( _t_ 1) _N_ _t_ ) (7)\n\n\n\n− _t_ _t_ _t_\n\n1( (1) )\n\n\n\n_t_\n\n\n\n(2) (2) (21) 1()\n(2) (2) _N_ _t_ + α _t_ _N_ _t_\n\n\n\n_dNdt_ _t_ = _r_ (2) _N_ _t_ (2) 1( − _N_ _t_ + _K_ α (2 _t_ ) _N_ _t_ ) (8)\n\n\n\n− _t_ _t_ _t_\n\n1( (2) )\n\n\n\n_t_\n\n\n( _ij_ )\nrespectively, and α _t_ [refers to the impact of an ]\n\n\nindividual of species _j_ on population growth of species _i_ ;\n\nhere _i_, _j_ ∈{ 1,2} Actually, The Lotka-Volterra model of\n\ninter-specific competition also includes the effects of\nintra-specific competition on population of the species ( _ij_ ) ( _i_ )\nWhen α _t_ or _N_ _t_ equals 0, the population of the\n\n\nspecies _j_ will grow according to the logistic growth\nmodel which models the intra competition between\nindividuals in a species These equations can be used to predict the outcome of\ncompetition over time To do this, we should determine\nequilibria, i e",
    "e the condition that population growth of\n\nboth species will be zero Let _dN_ _t_ (1) / _dt_ = 0 and\n\n_dN_ _t_ (2) / _dt_ = 0 If _r_ (1) _N_ _t_ (1) and _r_ (2) _N_ _t_ (2) do not equal\n\n\n0, we get two line equations which are called the\nisoclines of the species They can be plotted in four\ncases, as are shown in Fig 1 According to the figure,\nthere are four kinds of competition results determined by\n\nthe relationship between _K_ _t_ 1(), _K_ _t_ (2), α _t_ (12) and α _t_ (21) (a) When _K_ _t_ (2) / α _t_ (21) < _K_ _t_ (1), _K_ _t_ (1 / ) α _t_ (12) - _K_ _t_ (2) for\n\n\nall the time steps, species 1 will always win and the\n\nbalance point is _N_ _t_ (1) = _K_ _t_ (1), _N_ _t_ (2) = 0 (b) When _K_ _t_ (2) / α _t_ (21) - _K_ _t_ 1(), _K_ _t_ 1( / ) α _t_ (12) < _K_ _t_ (2) for\n\n\nall the time steps, species 2 will always win and the\n\nbalance point is _N_ _t_ (1 = ) 0, _N_ _t_ (2) = _K_ _t_ (2) (c) When _K_ _t_ (2) / α _t_ (21) < _K_ _t_ 1(), _K_ _t_ 1( / ) α _t_ (12) < _K_ _t_ (2) for\n\n\nall the time steps, they can win each other; the initial\npopulation of them determines who will win (d) When _K_ _t_ (2) / α _t_ (21) - _K_ _t_ (1), _K_ _t_ (1 / ) α _t_ (12) - _K_ _t_ (2) for\n\n\nall the time steps, there is only one balance point and\nthey can coexist with their own population size α _K_ _t_ ( _t_ (212)) _N_ _t_ (2) _K_ _t_ (1) _N_ _t_ (2)\n\n|K(2)<br>t<br>α(21)<br>t|N (1)<br>t|\n|---|---|\n|)<br>1<br>(<br>_t_<br>_K_<br>|)<br>1<br>(<br>_t_<br>_K_<br>|\n\n\n_K_ _t_ (2) α _K_ _t_ ( _t_ 12()1) α _K_ _t_ ( _t_ 12()1) _K_ _t_ (2)\n\n|Col1|Col2|Col3|N(2)<br>t|\n|---|---|---|---|\n|||||\n|)<br>12<br>(<br>)1<br>(<br>_t_<br>_t_<br>_K_<br>α<br>|)<br>12<br>(<br>)1<br>(<br>_t_<br>_t_<br>_K_<br>α<br>||)<br>2<br>(<br>_t_<br>_K_|\n|)<br>12<br>(<br>)1<br>(<br>_t_<br>_t_<br>_K_<br>α<br>||||\n|)<br>12<br>(<br>)1<br>(<br>_t_<br>_t_<br>_K_<br>α<br>|(b)|(b)|(b)|\n\n\n\n_K_ _t_ (1) _N_ _t_ (2) α _K_ _t_ ( _t_ (212)) _N_ _t_ (2)\n\n|Col1|N (1)<br>t|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|)<br>1<br>(<br>_t_<br>_K_<br>||||||\n|)<br>1<br>(<br>_t_<br>_K_<br>||||||\n|)<br>21<br>(<br>)<br>2<br>(<br>_t_<br>_t_<br>_K_<br>α||||||\n|)<br>21<br>(<br>)<br>2<br>(<br>_t_<br>_t_<br>_K_<br>α|||||)<br>2<br>(<br>_t_<br>_N_|\n||||)<br>2<br>(<br>_t_<br>_K_|||\n||||(a)|||\n|)<br>21<br>(<br>)<br>2<br>(<br>_t_<br>_t_<br>_K_<br>α||)<br>1(<br>_t_<br>_N_|)<br>1(<br>_t_<br>_N_|)<br>1(<br>_t_<br>_N_|)<br>1(<br>_t_<br>_N_|\n|)<br>21<br>(<br>)<br>2<br>(<br>_t_<br>_t_<br>_K_<br>α||||||\n|)<br>1<br>(<br>_t_<br>_K_<br>||||||\n\n\n\nα _t_ (12) α _t_ (12)\n\n|Col1|Col2|Col3|K(1)<br>t|\n|---|---|---|---|\n||||)<br>21<br>(<br>)<br>2<br>(<br>_t_<br>_t_<br>_K_<br>α|\n|||)<br>2<br>(<br>_t_<br>_N_|)<br>2<br>(<br>_t_<br>_N_|\n|)<br>2<br>(<br>_t_<br>_K_||||\n\n\n(c) (d)\n\n|Col1|N(2)<br>t|\n|---|---|\n||)<br>2<br>(<br>_t_<br>_K_|\n\n\n\nFig 1 The isoclines of two coevolution species\n\n\n\nFor an environment that includes Ω species, the\ncompetition equation can be modified as:\n\n\nΩ\n\n\n\n( _i_ ) ( _ij_ )\n# dNdt t ( i ) = r ( i ) N t ( i ) 1( − N t + j = ∑ K,1 j ( ≠ i α ) i t N\n\n\n\n( _i_ ) ( _ij_ ) ( _j_ )\n\n\n\n( _i_ ) ( _ij_ ) ( _j_\n# ( i ) N t + ∑ α t N t\n\n_t_ = _r_ ( _i_ ) _N_ _t_ ( _i_ ) 1( − _j_ = _K_,1 _j_ ( ≠ _i_ ) _i_\n\n\n\n_t_ + α _t_\n\n= ( _i_ ) ( _i_ ) − _j_ =,1 _j_ ≠ _i_\n\n\n\n(9)\n\n\n\n( _i_ )\n\n_t_ ( _i_ ) ( _i_ )\n\n\n\n− _j_ =,1 _j_ ≠ _i_\n\n1( ( _i_ ) )\n\n\n\n_j_ =,1 _j_ ≠ _i_\n\n\n\n( _i_\n\n\n_t_\n\n\n\n_n_\n\n\n# ( i ) = 2 n C ∏ d              (14)\n\n\n# A t ( i ) = 2 n C n ∏ d j\n\n_j_ = 1\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n_3 3 Environment Resources_\n\nEach species will occupy a part of the state space, which\n\n( _i_ )\nis called living domain of that species Let matrix _Q_ _t_\n\n\nrepresent the covariance matrix calculated using the\n\n( _i_ )\nindividuals in a species _i_ _Q_ _t_ is a symmetric matrix of\n\n\n( _i_ )\n_n_ × _n_, here _n_ is the dimension of the state Matrix _Q_ _t_\n\n\ncan be decomposed using singular value decomposition:\n_Q_ _t_ ( _i_ ) = _UDU_ _T_ (10)\n\n\n_n_ × _n_\n_U_ = ( 1 _e_ �,, _e_ _n_ ) ∈ _R_ (11)\n\n\n_D_ = _diag_ ( _d_ 1, �, _d_ _n_ ) (12)\n\n\nWhere _d_ is the variance of species _j_ _i_ in direction _[e]_ [, ] _j_\n\n\n_e_ ∈ _j_ _R_ _n_ is a unit vector, and\n\n_e_ _Tj_ ⋅ _e_ _k_ = ⎧⎨ 1 _j_ = _k_ (13)\n⎩ 0 _j_ ≠ _k_\n\nWe define the living domain of the species _i_ at time _t_ to\n\nbe an ellipsoid with radius of 2 _d_ _j_ in direction _[e]_ [, ] _j_\n\n\n( _i_ )\nand it is centered at ~~_[x]_~~ _t_ which is the weighted average\n\n\nof the individuals in species _i_ The size of the living\ndomain is decided by:\n\n\n_n_\n# A t ( i ) = 2 n C n ∏ d j              (14)\n\n_j_ = 1\n\n\nWhere _C_ is a constant, depending on _n_ _n_, for example\n\n\n_C_ 2 = π, _C_ 3 = 4 π / 3 Actually the living domain of a\n\n\nspecies reflects the uncertainty of the robot’s pose\nestimated according to that species, and it is similar to\nthe uncertainty ellipsoid (Herbert, M",
    "Actually the living domain of a\n\n\nspecies reflects the uncertainty of the robot’s pose\nestimated according to that species, and it is similar to\nthe uncertainty ellipsoid (Herbert, M _et al_, 1997) _et al_, 1997) Environment resources are proportional to the size of the\nliving domain The environment resources occupied by a\nspecies are defined as:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n_R_ ( _i_ ) = ⎪⎨δ⋅ _A_ _t_ _A_ _t_ - ε (15)\n\n\n\n( _i_ ) ⎧δ⋅ _A_ _t_ ( _i_ ) _A_ _t_ ( _i_ )\n\n\n\n( _i_ ) = ⎧δ⋅ _A_ _t_ ( _i_ ) _A_ _t_ ( _i_\n\n_t_ ⎪⎨\n\nδ⋅ε _A_\n\n\n\n⋅ _t_ _t_     - ε\n\n=\n\n⎪⎨δ⋅ε _A_ ( _i_ ) ≤ ε\n\n\n\n⎧⎪⎨\n\n⎪⎩\n\n\n\nδ⋅ _A_ _A_ - ε\n\n\n\n⋅ε _A_ ≤\n\n\n\n( _i_ )\n\n\n_t_\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhere δ is the number of resources in a unit living\ndomain, and ε is the minimum living domain a species\nshould maintain Assuming a species can plunder the\nresources of other species through competition, i e e the\nenvironment resources are shared by all species And the\nnumber of individuals that a unit of resource can support\nis different for species with different fitness The upper\nlimit of population size that the environment resources\ncan support of a species is determined by:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nα (\n\n\n\n\n\n\n\n\n\n_t_\n\n\n\n(c)\n\n\n\n\n\n186\n\n\n_K_ _t_ ( _i_ ) = exp(1 − ~~_w_~~ _t_ ( _i_ ) ) ⋅ _R_ _t_ (16)\n# Where parameter R t = ∑ i Ω= 1 R t ( i ) is the total resources\n\n\n( _i_ )\nof the system and ~~_[w]_~~ _t_ is the average importance factor\n\n\nof species _i_ It is obvious that the environment resources\nwill change over time In the beginning, the pose of the\nrobot is very uncertain, so the environment resources are\nabundant When the pose of robot becomes certain after\nrunning for some time, the living domains will become\nsmall and the environment resources will also be\n\nreduced The upper limit of population of species will\nchange according to the environment resources, but the\nchange of the resources will not affect the competition\n\nresults of the species Supposing _R_ _t_ = λ _R_ _t_ − 1 and there\n\n\nare two species, upper limit of the population of species\n\nwill be _K_ _t_ 1() = λ _K_ _t_ ( − 11) and _K_ _t_ (2) = λ _K_ _t_ ( − 21) This will not\n\nchange the relation between _K_ _t_ (2) / α _t_ (21) and _K_ _t_ (1), and\n\nthat between _K_ _t_ (1 / ) α _t_ (12) and _K_ _t_ (2) in the Lotka\n\nVolterra competition model _3 4",
    "4 Intra-Species Evolution_\nSince genetic algorithm and sequential Monte Carlo\nimportance sampling have many common aspects,\nHiguchi, T (1997) has merged them together In\nCEAMCL the genetic operators, crossover and mutation,\nare applied to search for optimal samples in each species\nindependently The intra-species evolution will interact\nwith inter-species competition: the evolution of\nindividuals in a species will increase its ability for interspecies competition, so as to survive for a longer time Because the observation density _p_ ( _y_ _t_ | _x_ _t_ ) includes\n\n\nthe most recent observed information of the robot, it is\ndefined as the fitness function The two operators:\ncrossover and mutation, work directly over the floatingpoints to avoid the trouble brought by binary coding and\ndecoding The crossover and mutation operator are\ndefined as following:\n\n( _p_ 1) ( _p_ 1)\nCrossover: for two parent samples ( _x_ _t_, _w_ _t_ ),\n\n\n( _p_ 2) ( _p_ 2)\n( _x_ _t_, _w_ _t_ ), the crossover operator mates them by\n\n\nformula (17) to generate two children samples ⎧⎪⎨\n\n⎪⎩\n\n\n\n( _c_ ) ( _p_ )\n\n\n\n_x_ _t_ _c_ = _x_ _t_ _p_ +τ\n\n_w_ _t_ ( _c_ ) = _p_ ( _y_ _t_ | _x_\n\n\n\n= _x_ +\n\n\n\n_x_ _t_ = _x_ _t_ +τ\n(18)\n\n\n\n_t_ ( _c_ ) = _p_ ( _y_ _t_ | _x_ _t_ ( _p_ ) )\n\n\n\n_t_ _c_ = _p_ ( _y_ _t_ | _x_ _t_ _p_\n\n\n\n=\n\n\n\n⎧\n\n⎪\n⎪\n\n⎨\n\n⎪\n⎪\n\n⎩\n\n\n\n( _c_ 1) ( _p_ 1) ( _p_ 2)\n\n\n\n_t_ _c_ = ξ _x_ _t_ _p_ + 1( − ξ ) _x_ _t_ _p_\n\n\n\n−\n\n1( ξ )\n\n\n\nξ _x_ _t_ _p_ + 1( − ξ )\n\n\n\n= _x_ + −\n\n\n\n_x_ = _x_ + − _x_\n\n\n\n( _c_ 2) ( _p_ 1) ( _p_ 2)\n\n\n\n_t_ _c_ = 1( − ξ ) _x_ _t_ _p_ + ξ _x_ _t_ _p_\n\n\n\n(17)\n\n\n\n−\n\n1( ξ )\n\n\n\nξ ) _x_ _t_ _p_ + ξ _x_\n\n\n\n= − _x_ +\n\n\n\n_x_ = − _x_ + _x_\n\n\n\nWhere τ ~ _N_ (,0 Σ ) is a three-dimensional vector and\n_N_ (,0 Σ ) represents normal distribution The sample\n\nwith larger importance factor is selected from the two\nsamples for next generation In CEAMCL, the crossover\noperator will perform with probability _[p]_ [ and mutation ] _c_\n\n\noperator will perform with probability _p_ Because the _m_\n\n\ngenetic operator can search for optimal samples, the\nsampling process is more efficient and the number of\nsamples required to represent the posterior density can\nbe reduced considerably",
    "Because the _m_\n\n\ngenetic operator can search for optimal samples, the\nsampling process is more efficient and the number of\nsamples required to represent the posterior density can\nbe reduced considerably _3 5 5 CEAMCL Algorithm_\nThe coevolution model is merged into the MCL, and the\nnew algorithm is termed coevolution based adaptive\nMonte Carlo localization (CEAMCL) During\nlocalization, if two species cover each other and there is\nno valley of importance factor between them, they will\nbe merged; and a species will be split if grids occupied\nby the samples can be split into more than one connected\nregions as in initial species generation This is called\nsplitting-merging process The CEAMCL algorithm is\ndescribed as following:\n\n- Initialization: select initial samples and cluster\nthe samples into Ω species; for each species _i_, let\n_dN_ 0( _[i]_ ) / _dt_ =0; and let _t_ =1 - Sample size determination: if _dN_ _t_ ( − _[i]_ 1) / _dt_ - 0,\n\ndraw _dN_ _t_ ( − _[i]_ 1) / _dt_ samples randomly from the living\n\n\ndomain of the _i_ th species and merge the newly drawn\n\nsamples to _[S]_ _t_ ( − _i_ 1) [; let ] _N_ _t_ ( _i_ ) = max( _N_ _t_ ( − _i_ )1 [+] _dN_ _t_ ( − _i_ )1 / _dt_ 0,)\n\n- Resampling: for each species _i_, resample _N_ _t_ ( _i_ )\n\n\n( _i_ ) ( _i_ )\nsamples from _[S]_ _t_ − 1 [ according to ] _w_ _t_ − 1 ;\n\n\n- Importance Sampling: for each species _i_,\n\n( _ij_ ) ( _ij_ )\nsample state _[x]_ _t_ from _p_ ( _x_ _t_ | _x_ _t_ − 1, _u_ _t_ − 1 ) for each of\n\nthe _N_ _t_ ( _i_ ) possible state _[x]_ _t_ ( − _ij_ 1) [; and evaluate the ]\n\nimportance factor _w_ _t_ ( _ij_ ) = _p_ ( _y_ _t_ | _x_ _t_ ( _ij_ ) ) - Intra-species evolution: for each species _i_\nrandomly draw two samples _,_ and mate them with\n\nprobability _[p]_ [, repeat this for ] _c_ _N_ _t_ ( _i_ ) /2 times; then\n\n\nrandomly draw one sample from species _i,_ and mutate it\n\n( _i_ )\nwith probability _p_, repeat this for _m_ _N_ _t_ times - Splitting-merging process: split and merge the\nspecies using the rules defined in the splitting-merging\n\nprocess - Calculating the sample size increment: for each\nspecies i calculate the upper limit population size of\n\nspecies _i_, and calculate _dN_ _t_ ( _[i]_ ) / _dt_ using equation (9) 187\n\n\n\nt( _c_ 1) = _p_ ( _y_ _t_ | _x_ _t_ ( _c_ 1)\n\n\n( _c_ 2) ( _c_ 2)\n\n\n\n_c_ _c_\n\n= _p_ ( _y_ _t_ | _x_ _t_\n\n\n\n_w_ t = _p_ _y_ _t_ _x_\n\n\n\n=\n\n\n\n_c_ _c_\n_t_ = _p_ ( _y_ _t_ | _x_ _t_\n\n\n\n_w_ _t_ = _p_ _y_ _t_ _x_\n\n\n\n=\n\n\n\n_c_\n\n( _y_ _t_ | _x_ _t_ )\n\n\n( _c_ 2)\n\n( _y_ _t_ | _x_ _t_ )\n\n\n\nWhere ξ ~ _U_ [1,0], and _U_ []1,0 represents uniform\n\ndistribution And two samples with the largest\nimportance factors are selected from the four samples for\nthe next generation ( _p_ ) ( _p_ )\nMutation: for a parent sample ( _x_ _t_, _w_ _t_ ), the\n\n\nmutation operator on it is defined by formula (18) - Summary: The species whose average\nimportance factor is the largest is assumed to be the\nlocation of the robot, and the importance factors of each\nspecies are normalized independently - _t_ = _t_ +1; go to step _2)_ if not stop _3,6",
    "_3,6 Computational Cost_\nCompared with MCL, CEAMCL requires more\ncomputation for each sample But the sampling process\nis more efficient in CEAMCL So it can considerably\nreduce the number of samples required to represent the\nposterior density The resampling, importance factor normalization and\ncalculating statistic properties have almost the same\ncomputational cost per sample for the two algorithms We denote the total cost of each sample in these\ncalculations as _T_ _r_ The importance sampling step\ninvolves drawing a _n_ dimensional-vector according to\n\nthe motion model _p_ ( _x_ _t_ | _x_ _t_ ( − _j_ 1), _u_ _t_ − 1 ) and computing the\n\n\nimportance factor whose computational costs are\ndenoted as _T_ _s_ and _T_ _f_ respectively The additional\ncomputational cost for CEAMCL arises from the intraspecies evolution step and the splitting-merging process The evolution step computes the importance factor with\n\nprobability _[p]_ [ in crossover and with probability ] _c_ _p_ in _m_\n\n\nmutation The other computation in evolution step\nincludes drawing a _n_ dimensional-vector from a\nGaussian distribution, drawing a random number from\nuniform distribution of _U_ [0,1] and several times of\nsimple addition, multiplication and comparison Since\nthe other computational cost in evolution step is almost\nthe same as _T_ _s_ which also includes drawing a _n_\ndimensional-vector from a Gaussian distribution, the\ntotal computational cost for each sample in evolution\nstep is approximated by ( _p_ _c_ + _p_ _m_ ) _T_ _f_ + _T_ _s_ The splitting or\nmerging probability of species in each time step is small,\nespecially when the species become stable no species\nneed to be split or merged, so the computational cost of\nthe splitting-merging process denoted as _T_ _m_ is small And\nthe computational costs of other steps in CEAMCL are\nnot related to the sample size, so they can be neglected Defining _N_ _M_ and _N_ _C_ as the number of samples in MCL\nand CEAMCL respectively, the total computational costs\nfor one of the iteration in localization _T_ _M_ and _T_ _C_ are\ngiven by:\n\n_T_ _M_ = _N_ _M_ ( _T_ _f_ + _T_ _s_ + _T_ _r_ ) (19)\n\n\n_T_ _C_ ≈ _N_ _C_ ((1 + _p_ ) ⋅ _T_ _f_ + 2 _T_ _s_ + _T_ _r_ + _T_ _m_ ) (20)\n\n\nWhere _p_ = _p_ _c_ + _p_ _m_ The most computationally\n\n\nintensive procedure in localization is the computation of\nthe importance factor which has to deal with the high\ndimensional sensor data, so _[T]_ [ is much larger than the ] _f_\n\n\nother terms It is safe to draw the following rule:\n\n\n_T_ _C_ ≈ 1( + _p_ ) ⋅ _T_ _M_ ( _N_ _C_ / _N_ _M_ ) (21)\n\n\n188\n\n\n\n**4",
    "It is safe to draw the following rule:\n\n\n_T_ _C_ ≈ 1( + _p_ ) ⋅ _T_ _M_ ( _N_ _C_ / _N_ _M_ ) (21)\n\n\n188\n\n\n\n**4 Experimental Results**\n\nWe have evaluated CEAMCL in the context of indoor\n\nmobile robot localization using data collected with a\n\nPioneer Ⅱ robot The data consist of a sequence of laser\n\nrange-finder scans along with odometry measurements\nannotated with time-stamps to allow systematic real-time\nevaluations The experimental field is a large hall in our\nlaboratory building whose size is of 15 × 15 m [2], and the\nhall is partitioned into small rooms using boards to form a\nhighly symmetric map shown in Fig 2 In the initial species generation, we only use the x-y\nposition and don’t use direction to cluster the samples The map is divided into 150 × 150 grids The test\nsample size _N_ _test_ equals 1000000; the threshold\n\nparameter µ equals 0 85; and parameter η is 2 The\n\ninitial species generation results are shown in Fig 2 It is\nobvious that even in the same environment the initial\n\nsample sizes are different when the robot is placed in\ndifferent places The real position of robot is marked\nusing a small circle (a)                      (b)\nFig 2 2 The initial species for localization (a) 4 species\nwith 537 samples (b) 8 species with 961 samples\n\nIn the localization experiments, the robot was placed at\nthe center of one of the four rooms, and it was\ncommanded to go to a corner of another room 5 times of\nexperiments were conducted for each center The three\nalgorithms MCL, GMCL and CEAMCL were applied to\nlocalize the robot using the data collected in the\nexperiments Here GMCL is genetic Monte Carlo\nlocalization which merges genetic operators into MCL\nbut without coevolution mechanism The parameter\n\nα _t_ ( _ij_ ) = _w_ _t_ ( _j_ ) / _w_ _t_ ( _i_ ), where ~~_[w]_~~ _t_ ( _i_ ) is the fitness (average\n\n\n( _i_ )\nimportance factor) of species _i_ ; parameter _r_, the\nmaximum possible rate of population growth of species,\nequals 0 2; and parameter ε, the minimum living\ndomain of species, equals 0 5m [2] ; parameter δ, the\nnumber of resources in a unit living domain which is 1\nm [2] in this paper, equals 80; the crossover probability\n\n\n_[p]_ [ is 0 85; and the mutation probability ] _c_ _p_ is 0 15 _m_\n\n\nThe success rate of the three algorithms to track the\nhypothesis corresponding to the robot’s real pose until\nthe robot reaches the goal is shown in table 1 In table 1,\nthe converged time is the time when the samples\nconverged to the four most likely positions; the expired\n\n\ntime is the time when one of the hypotheses vanished The data shows that the CEMCL can converge to the\nmost likely positions as fast as GMCL, but it can\nmaintain the hypotheses for a much longer time than the\nother two algorithms This is because the species with\nmuch lower fitness will die out because of the\n\ncompetition between species, and the species with\nsimilar fitness can coexist with each other for a longer\ntime Figure 3 shows two inter moments when the robot\nran from the center of room 1 to the goal using the\nCEAMCL algorithm |Col1|CEAMCL|GMCL|MCL|\n|---|---|---|---|\n|Converged time (s)|6 87|6 41|9 76|\n|Expired time (s)|Never|30 44|36 4<br>6|\n|Success rate|100%|82%|86%|\n\n\n\nTable 1 Success rate of multi-hypotheses tracking\n\n(a)                     (b)\nFig 3",
    "3 Localization based on CEAMCL (a) samples at\n7th second  (b) samples at 16th second\n\nTo compare the localization precision of the three\nalgorithms, we use the robot position tracked by using\nMCL with 5000 samples in the condition of knowing the\ninitial position to be the reference robot position The\naverage estimation errors along the running time are\nshown in Fig 4 Since the summary in CEAMCL is\nbased on the most likely species and the genetic operator\nin intra-species evolution can drive the samples to the\nregions with large importance factors, so localization\nerror of CEAMCL is much lower Although GMCL\nalmost has the same precision as CEAMCL after some\ntime, GMCL is much more likely to produce premature\nconvergence in symmetric environment The computational time needed for each iteration with\n961 initial samples on a computer with a CPU of\nPENIUM� 800 is shown in Fig 5 Because\n_p_ _c_ + _p_ _m_ = 1, the computational time needed for each\n\n\niteration of CEAMCL is almost twice of that of MCL\n\nwith the same size of sample set But since the sample\nsize of CEAMCL is adaptively adjusted during the\nlocalization process, the computational time for each\niteration of CEAMCL becomes less than that of MCL\n\nafter some time But since the sample\nsize of CEAMCL is adaptively adjusted during the\nlocalization process, the computational time for each\niteration of CEAMCL becomes less than that of MCL\n\nafter some time From Fig 4 and Fig 5 we can see that\nthe CEAMCL can make precise localization with a small\nsample size The changes of the total environment\nresources and the total number of samples are shown in\n\n\n\nFig 6 From the figure we can see that the resources will\nbe reduced when the position becomes certain, the total\nsample size needed for robot localization will also be\nreduced The parameter δ which represents the number of\nresources in a unit living domain is important in\nCEAMCL, because it will affect the competition\nbetween species Large δ will reduce the competition\nbetween the species since there is enough resource for\nthem The curve of total sample size with different δ is\n\n\n( _i_ )\nshown in Fig 7 The growth rate _r_ is another\n\n( _i_ )\nimportant parameter Large _r_ will increase the rate of\nconvergence to the species that have larger fitness But if\n( _i_ )\n_r_ is too large it may cause premature convergence 200\n\n\n\n175\n\n\n150\n\n\n\n\n\n125\n\n\n100\n\n\n75\n\n\n50\n\n\n25\n\n\n0\n5 10 15 20 25 30 35 40\n\n\nTime [sec]\n\n\nFig 4 Estimation Error\n\n\n\n45\n\n\n40\n\n\n35\n\n\n30\n\n\n25\n\n\n20\n\n\n15\n\n\n10\n\n\n5\n\n\n\n\n\n0\n0 5 10 15 20 25 30 35 40\n\n\nTime [sec]\n\n\nFig 5 Computational time for each iteration\n\n\n\n1000\n\n\n900\n\n\n800\n\n\n700\n\n\n600\n\n\n500\n\n\n400\n\n\n300\n\n\n200\n\n\n100\n\n\n\n\n\n0\n0 5 10 15 20 25 30 35 40\n\n\nTime [sec]\n\n\nFig 6 Change of resource and sample size\n\n\n\n189\n\n\n1000\n\n\n900\n\n\n800\n\n\n700\n\n\n600\n\n\n500\n\n\n400\n\n\n300\n\n\n200\n\n\n100\n\n\n\n\n\n0\n0 5 10 15 20 25 30 35 40\n\n\nTime [sec]\n\nFig 7 Effect of δ on sample size\n\n**5",
    "Effect of δ on sample size\n\n**5 Conclusion**\n\nAn adaptive localization algorithm CEAMCL is\nproposed in this paper Using an ecological competition\nmodel, CEAMCL can adaptively adjust the sample size\naccording to the total environment resource, which\nrepresents uncertainty of the position of the robot Coevolution between species ensures that the problem of\npremature convergence when using MCL in highly\nsymmetric environments can be solved And genetic\noperators used for intra-species evolution can search for\noptimal samples in each species, so the samples can\nrepresent the desired posterior density better Experiments prove that CEAMCL has the following\nadvantages: (1) it can adaptively adjust the sample size\nduring localization; (2) it can make stable localization in\nhighly symmetric environment; (3) it can make precise\nlocalization with a small sample size Experiments prove that CEAMCL has the following\nadvantages: (1) it can adaptively adjust the sample size\nduring localization; (2) it can make stable localization in\nhighly symmetric environment; (3) it can make precise\nlocalization with a small sample size **6 References**\n\nAndrieu, C & Doucet, A (2002) Particle filtering for\npartially observed gaussian state space Models _Journal of the Royal Statistical Society Series B_\n_(Statistical Methodology)_, Vol 64, No 4, pp 827-836\nBurgard, W , Fox, D , Hennig, D , & Schmidt, T (1996) (1996) Estimating the absolute position of a mobile robot\nusing position probability grids, In: Proc of the\nNational Conference on Artificial Intelligence (AAAI1996), pp 896-901, AAAI Press, Oregon, USA\nChen, M & Zalzala, A (1995) (1995) Safety considerations in\nthe optimization of paths for mobilerobots using\ngenetic algorithms, In: Proc of First International\nConference on Genetic Algorithms in Engineering\nSystems: Innovations and Applications, pp",
    "of First International\nConference on Genetic Algorithms in Engineering\nSystems: Innovations and Applications, pp 299-304,,\nIEE Press, Halifax, UK\nDellaert, F , Fox, D , Burgard, W , & Thrun, S (1999) Monte Carlo localization for mobile robots, In: Proc of the IEEE International Conference on Robotics and\n\nAutomation, pp 1322-1328, IEEE Press, Michigan,\nUSA\n\nDuckett, T (2003) (2003) A genetic algorithm for simultaneous\nlocalization and mapping, In: Proc of the IEEE\nInternational Conference on Robotics and\nAutomation, pp, 434-439, IEEE Press, Taiwan,\nChina\n\n\n190\n\n\n\nFox, D (2003) Adapting the sample size in particle filters\nthrough KLD-Sampling International _Journal of Robotic_\n_Research_, Vol 22 No 12, pp 985-1004\nHiguchi, T (1997) Monte Carlo Filtering using genetics\nAlgorithm Operators _Journal of Statistical Computation_\n_and Simulation_ 59, pp 1-23\nJensfelt, P & Kristensen, S (2001) (2001) Active global\nlocalization for a mobile robot using multiple hypothesis\ntracking Active global\nlocalization for a mobile robot using multiple hypothesis\ntracking _IEEE Trans Robotics Automation_, Vol 17, No 5, pp 748-760 Kaelbling, L P , Cassandra, A R , & Kurien, J A (1996) (1996) Acting under uncertainty: Discrete Bayesian models for\nmobile-robot navigation, In: Proc of the IEEE/RSJ\nInternational Conference on Intelligent Robots and\nSystems, pp 963-972, IEEE Press, Osaka, Japan\nKoller, D & Fratkina, R (1998) (1998) Using learning for\napproximation in stochastic processes, In: Proc of the\nInternational Conference on Machine Learning, Lorenza\nSaitta (Ed ), pp 287-295, Morgan Kaufmann Press, Bari,\nItaly\nLeonard, J J & Durrant-Whyte, H F (1991) (1991) Mobile robot\nlocalization by tracking geometric beacons _IEEE Trans _\n_Robotics Automation_, Vol 7, No 3, pp 376-382\nMoreno, L , Armingol, J M , & Garrido, S , et al (2002)",
    "(2002) A\ngenetic algorithm for mobile robot localization using\nultrasonic sensors _Journal of Intelligent and Robotic_\n_Systems_ 34, pp 135-154\nMoriarty, D E & Miikkulainen, R (1997) Forming neural\nnetworks through efficient and adaptive coevolution _Evolutionary Computation_, Vol 5, No 4, pp 373-399\nPotter, M A & De Jong, K A (2000) (2000) Cooperative\ncoevolution: An architecture for evolving coadapted\nsubcomponents _Evolutionary Computation_, Vol 8, No 1, pp 1-29\nPotvin, J , Duhamel, C , & Guertin, F (1996) A genetic\nalgorithm for vehicle routing with backhauling _Applied_\n_Intelligence_ 6, pp 345-355\nRosin, C , & Belew, R (1997) New methods for\ncompetitive co-evolution _Evolutionary Computation_,\nVol 5, No 1, pp 1-29\nRoumeliotis, S I & Bekey, G A (2000) Bayesian\nestimation and Kalman filtering: A unified framework for\nmobile robot localization, In: Proc of the IEEE\nInternational Conference on Robotics and Automation,\npp 2985-2992, IEEE Press, San Francisco, USA\nSerra, J (1982) _Image Analysis and Mathematical_\n_Morphology_ _Image Analysis and Mathematical_\n_Morphology_ Academic Press, New York\nSimmons, R and Koenig, S (1995) (1995) Probabilistic robot\nnavigation in partially observable environments, In: Proc of the International Joint Conference on Artificial\n\nIntelligence, pp 1080-1087, Morgan Kaufmann Press,\nQuebec, Canada\nThrun, S , Fox, D , Burgard, W & Dellaert, F (2001) Robust Monte Carlo localization for mobile robots _Artificial Intelligence_ 128, pp 99-141\nYuchang, S & Xiaoming, C (1996) _Common Ecology_,\nBeijing University Press (in Chinese), Beijing\n\nThis work was found in part by the National Natural\nScience Foundation of China (No 69985002)"
  ]
}