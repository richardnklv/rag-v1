{
  "filename": "Online_Simultaneous_State_and_Parameter_Estimation.pdf",
  "text_length": 47731,
  "chunk_count": 11,
  "chunks": [
    "## Simultaneous State and Parameter Estimation for Second-Order Nonlinear Systems\n\nRushikesh Kamalapurkar\n\n\n\n_**Abstract**_ **— In this paper, a concurrent learning based adap-**\n**tive observer is developed for a class of second-order nonlinear**\n**time-invariant systems with uncertain dynamics The developed**\n**technique results in uniformly ultimately bounded state and**\n**parameter estimation errors As opposed to** _**persistent**_ **excitation**\n**which is required for parameter convergence in traditional**\n**adaptive control methods, the developed technique only requires**\n**excitation over a finite time interval to achieve parameter**\n**convergence Simulation results in both noise-free and noisy**\n**environments are presented to validate the design **\n\n\nI **\n\n\nI I NTRODUCTION\n\n\nOwing to Increasing reliance on automation and increasing\ncomplexity of autonomous systems, the ability to adapt\nhas become an indispensable feature of modern control\nsystems Traditional adaptive control methods (see, e Traditional adaptive control methods (see, e g ,\n\n[1]–[3]) attempt to improve the tracking performance, and\nin general, do not focus on parameter estimation While\naccurate parameter estimation can improve robustness and\ntransient performance of adaptive controllers, (see, e While\naccurate parameter estimation can improve robustness and\ntransient performance of adaptive controllers, (see, e g g , [4]–\n\n[6]), parameter convergence typically requires restrictive\nassumptions such as persistence of excitation An excitation\nsignal is often added to the controller to ensure persistence of\nexcitation; however, the added signal can cause mechanical\nfatigue and compromise the tracking performance Parameter convergence can be achieved under a finite\nexcitation condition using data-driven methods such as concurrent learning (see, e Parameter convergence can be achieved under a finite\nexcitation condition using data-driven methods such as concurrent learning (see, e g , [6]–[8]), where the parameters\nare estimated by storing data during time-intervals when\nthe system is excited, and then utilizing the stored data to\ndrive adaptation when excitation is unavailable Concurrent\nlearning has been shown to be an effective tool for adaptive\ncontrol (see, e",
    "Concurrent\nlearning has been shown to be an effective tool for adaptive\ncontrol (see, e g , [6]–[9]) and adaptive estimation (see, e g g ,\n\n[10]–[15]), however, concurrent learning typically requires\nfull state feedback along with accurate numerical estimates\nof the state-derivative Novel concurrent learning techniques that can be implemented using full state measurements but without numerical\nestimates of the state-derivative are developed in [16] and\n\n[17]; however, since full state feedback is typically not\navailable, the development of an output-feedback concurrent\nlearning framework is well-motivated An output feedback\nconcurrent learning technique is developed for second-order\nlinear systems in [18]; however, the implementation critically\ndepends on the certainty equivalence principle, and hence, is\nnot directly transferable to nonlinear systems Rushikesh Kamalapurkar is with the School of Mechanical and\nAerospace Engineering, Oklahoma State University, Stillwater, OK, USA rushikesh kamalapurkar@okstate edu In this paper, an output feedback concurrent learning\nmethod is developed for simultaneous state and parameter\nestimation in second-order uncertain nonlinear systems An\nadaptive state-observer is utilized to generate estimates of the\nstate from input-output data The estimated state trajectories\nalong with the known inputs are then utilized in a novel datadriven parameter estimation scheme to achieve simultaneous\nstate and parameter estimation Convergence of the state estimates and the parameter estimates to a small neighborhood\nof the origin is established under a finite (as opposed to\n_persistent_ ) excitation condition The paper is organized as follows An integral error system\nthat facilitates parameter estimation is developed in Section\nII Section III is dedicated to the design of a robust state\nobserver Section IV details the developed parameter estimator Section V details the algorithm for selection and storage\nof the data that is used to implement concurrent learning Section VI is dedicated to a Lyapunov-based analysis of the\ndeveloped technique Section VII demonstrates the efficacy\nof the developed method via a numerical simulation and\nSection VIII concludes the paper II E RROR S YSTEM FOR E STIMATION\n\n\nConsider a second order nonlinear system of the form [1]\n\n\n_p_ ˙ ( _t_ ) = _q_ ( _t_ ) _,_\n\n\n_q_ ˙ ( _t_ ) = _f_ ( _x_ ( _t_ ) _, u_ ( _t_ )) _,_\n\n\n_y_ ( _t_ ) = _p_ ( _t_ ) _,_ (1)\n\n\nwhere _p_ : R _≥T_ 0 _→_ R _[n]_ and _q_ : R _≥T_ 0 _→_ R _[n]_ denote\nthe generalized position states and the generalized velocity\nstates, respectively, _x_ ≜ � _p_ _[T]_ _q_ _[T]_ [ �] _[T]_ is the system state,\n_f_ : R _[n]_ _×_ R _[m]_ _→_ R _[n]_ is locally Lipschitz continuous, and\n_y_ : R _≥T_ 0 _→_ R _[n]_ denotes the output The model _f_ is\ncomprised of a known nominal part and an unknown part,\ni e , _f_ = _f_ _[o]_ + _g_, where _f_ _[o]_ : R _[n]_ _×_ R _[m]_ _→_ R _[n]_ is known\nand locally Lipschitz and _g_ : R _[n]_ _×_ R _[m]_ _→_ R _[n]_ is unknown\nand locally Lipschitz The objective is to design an adaptive\nestimator to identify the unknown function _g_, online, using\ninput-output measurements It is assumed that the system\nis controlled using a stabilizing input, i e , _x, u ∈L_ _∞_ It\nis further assumed that the signal _p_, and _u_ are available\nfor feedback Systems of the form (1) encompass secondorder linear systems and Euler-Lagrange models, and hence,\nrepresent a wide class of physical plants, including but not\n\n\n1 For _a ∈_ R _,_ the notation R _≥a_ denotes the interval [ _a, ∞_ ) and the\nnotation R _>a_ denotes the interval ( _a, ∞_ ) limited to robotic manipulators and autonomous ground,\naerial, and underwater vehicles Given a compact set _χ ⊂_ R _[n]_ _×_ R _[m]_, and a constant\n~~_ϵ_~~ ~~,~~ the unknown function _g_ can be approximated using\nbasis functions as _g_ ( _x, u_ ) = _θ_ _[T]_ _σ_ ( _x, u_ ) + _ϵ_ ( _x, u_ ), where\n_σ_ : R _[n]_ _×_ R _[m]_ _→_ R _[p]_ and _ϵ_ : R _[n]_ _×_ R _[m]_ _→_ R _[n]_ denote\n\nthe basis vector and the approximation error, respectively,\n_θ ∈_ R _[p][×][n]_ is a constant matrix of unknown parameters,\nand there exist ~~_σ,_~~ _θ >_ 0 such that sup ( _x,u_ ) _∈χ_ _σ_ ( _x, u_ ) _<_\n~~_σ_~~ ~~,~~ sup ( _x,u_ ) _∈χ_ _∇σ_ ( _x, u_ ) _<_ ~~_σ_~~ ~~,~~ sup ( _x,u_ ) _∈χ_ _ϵ_ ( _x, u_ ) _<_ ~~_ϵ_~~ ~~,~~\nsup ( _x,u_ ) _∈χ_ _∇ϵ_ ( _x, u_ ) _<_ ~~_ϵ_~~ ~~,~~ and _∥θ∥_ _< θ_ To obtain an\nerror signal for parameter identification, the system in (1)\nis expressed in the form\n\n\n_q_ ¨ ( _t_ ) = _f_ _[o]_ ( _x_ ( _t_ ) _, u_ ( _t_ ))+ _θ_ _[T]_ _σ_ ( _x_ ( _t_ ) _, u_ ( _t_ ))+ _ϵ_ ( _x_ ( _t_ ) _, u_ ( _t_ )) _ _\n(2)\nIntegrating (2) over the interval [ _t −_ _τ_ 1 _, t_ ] for some constant\n_τ_ 1 _∈_ R _>_ 0 and then over the interval [ _t −_ _τ_ 2 _, t_ ] for some\nconstant _τ_ 2 _∈_ R _>_ 0,\n\n\n\n_t_\nˆ\n\n_t−τ_ 2\n\n\n\n( _q_ ( _λ_ ) _−_ _q_ ( _λ −_ _τ_ 1 )) d _λ_ = _If_ _[o]_ ( _t_ ) + _θ_ _[T]_ _Iσ_ ( _t_ ) + _Iϵ_ ( _t_ ) _,_\n\n\n\nIII V ELOCITY ESTIMATOR DESIGN\n\n\nTo generate estimates of the generalized velocity, a velocity estimator inspired by [19] is developed The estimator is\ngiven by\n\n\n_p_ ˙ˆ = ˆ _q_\n\n˙ˆ\n_q_ = _f_ _[o]_ (ˆ _x, u_ ) + ˆ _θ_ _[T]_ _σ_ (ˆ _x, u_ ) + _ν,_ (9)\n\n\nwhere ˆ _x_, ˆ _p_, ˆ _q,_ and _θ_ [ˆ] are estimates of _x, p, q,_ and _θ_,\nrespectively, and _ν_ is a feedback term designed in the\nfollowing ˜ To facilitate the design ofˆ _ν_, let ˜ _p_ = _p −_ _p_ ˆ, ˜ _q_ = _q −_ _q_ ˆ,\n_θ_ = _θ −_ _θ_, and let\n\n\n_r_ ( _t_ ) = _p_ ˜ [˙] ( _t_ ) + _αp_ ˜ ( _t_ ) + _η_ ( _t_ ) _,_ (10)\n\n\nwhere the signal _η_ is added to compensate for the fact that\nthe generalized velocity state, _q_, is not measurable Based on\nthe subsequent stability analysis, the signal _η_ is designed as\nthe output of the dynamic filter\n\n\n˙ ˜\n_η_ ( _t_ ) = _−βη_ ( _t_ ) _−_ _kr_ ( _t_ ) _−_ _αq_ ( _t_ ) _,_ _η_ ( _T_ 0 ) = 0 _,_ (11)\n\n\nwhere _α, k,_ and _β_ are positive constants and the feedback\ncomponent _ν_ is designed as\n\n\n_ν_ ( _t_ ) = _α_ [2] _p_ ˜ ( _t_ ) _−_ ( _k_ + _α_ + _β_ ) _η_ ( _t_ ) _ _ (12)\n\n\nThe design of the signals _η_ and _ν_ to estimate the state from\noutput measurements is inspired by the _p−_ filter [20] Using\nthe fact that ˜ _p_ ( _T_ 0 ) = 0, the signal _η_ can be implemented\nvia the integral form\n\n\n\n(3)\nwhere _I_ denotes the integral operator _f_ _�→_\n_t_ _λ_\n´ _t−τ_ 2 ´ _λ−τ_ 1 _[f]_ [ (] _[x]_ [ (] _[τ]_ [)] _[, u]_ [ (] _[τ]_ [))][ d] _[τ]_ [d] _[λ]_ [ Using the Fundamental]\nTheorem of Calculus and the fact that _q_ ( _t_ ) = ˙ _p_ ( _t_ ), the\nexpression in (4) can be rearranged to form the affine\n\nsystem\n\n\n_P_ ( _t_ ) = _F_ ( _t_ ) + _θ_ _[T]_ _G_ ( _t_ ) + _E_ ( _t_ ) _, ∀t ∈_ R _≥T_ 0 (4)\n\n\nwhere\n\n\n\n_t_\n\n\n( _β_ + _k_ ) _η_ ( _τ_ ) d _τ_ _−_\n\nˆ\n\n_T_ 0\n\n\n\n_η_ ( _t_ ) = _−_\n\n\n\n_t_\nˆ\n\n_T_ 0\n\n\n\n˜\n_kαp_ ( _τ_ ) d _τ_ _−_ ( _k_ + _α_ ) ˜ _p_ ( _t_ ) _ _\n\n\n\n_p_ ( _t−τ_ 2 _−τ_ 1 ) _−p_ ( _t−τ_ 1 )\n\n\n\n_P_ ( _t_ ) ≜\n\n\n\n\n\n\n\n+ _p_ ( _t_ ) _−p_ ( _t−τ_ 2 ) _,_ _t_ _∈_ [ _T_ 0 + _τ_ 1 + _τ_ 2 _, ∞_ ) _,_\n\n\n\n0 _t < T_ 0 + _τ_ 1 + _τ_ 2 _ _\n(5)\n\n\n\n_F_ ( _t_ ) ≜\n\n\n\n_If_ _[o]_ ( _t_ ) _,_ _t ∈_ [ _T_ 0 + _τ_ 1 + _τ_ 2 _, ∞_ ) _,_\n(6)\n�0 _,_ _t < T_ 0 + _τ_ 1 + _τ_ 2 _,_\n\n\n\n(13)\nThe affine error system in (4) motivates the adaptive\nestimation scheme that follows The design is inspired by\nthe _concurrent learning_ technique [21] Concurrent learning\nenables parameter convergence in adaptive control by using\nstored data to update the parameter estimates Traditionally,\nadaptive control methods guarantee parameter convergence\nonly if the appropriate PE conditions are met [1, Chapter\n4] Concurrent learning uses stored data to soften the PE\ncondition to an excitation condition over a finite timeinterval Concurrent learning methods such as [6] and [8]\nrequire numerical differentiation of the system state, and\nconcurrent learning techniques such as [17] and [16] require\nfull state measurements In the following, a concurrent\nlearning method that utilizes only the output measurements\nis developed",
    "In the following, a concurrent\nlearning method that utilizes only the output measurements\nis developed IV P ARAMETER E STIMATOR D ESIGN\n\n\nTo obtain output-feedback concurrent learning update law\nfor the parameter estimates, a history stack, denoted by\n_H_, is utilized The history stack is a set of ordered pairs\n_M_\n_P_ _i_ _,_ _F_ [ˆ] _i_ _,_ _G_ [ˆ] _i_\n�� �� _i_ =1 [such that]\n\n\n_P_ _i_ = _F_ [ˆ] _i_ + _θ_ _[T]_ [ ˆ] _G_ _i_ + _E_ _i_ _, ∀i ∈{_ 1 _, · · ·, M_ _},_ (14)\n\n\n\n_G_ ( _t_ ) ≜\n\n\n\n_Iσ_ ( _t_ ) _,_ _t_ _∈_ [ _T_ 0 + _τ_ 1 + _τ_ 2 _, ∞_ ) _,_\n(7)\n�0 _t < T_ 0 + _τ_ 1 + _τ_ 2 _,_\n\n\n\nand\n\n\n\n_E_ ( _t_ ) ≜\n\n\n\n_Iϵ_ ( _t_ ) _,_ _t ∈_ [ _T_ 0 + _τ_ 1 + _τ_ 2 _, ∞_ ) _,_\n(8)\n0 _t < T_ 0 + _τ_ 1 + _τ_ 2 _ _\n�\n\n\n\nThe affine relationship in (4) is valid for all _t ∈_ R _≥T_ 0 ;\nhowever, it provides useful information about the vector _θ_\nonly after _t ≥_ _T_ 0 + _τ_ 1 + _τ_ 2 The knowledge of the generalized velocity, _q_, is required\nto compute the matrices _F_ and _G_ In the following, a robust\nadaptive velocity estimator is developed to generate estimates\nof the generalized velocity In the following, a robust\nadaptive velocity estimator is developed to generate estimates\nof the generalized velocity where _E_ _i_ is a constant matrix If a history stack that satisfies\n(14) is not available a priori, it is recorded online, based\non the relationship in (4), by selecting an increasing set of\ntime-instances _{t_ _i_ _}_ _[M]_ _i_ =1 [and letting]\n\n\n_P_ _i_ = _P_ ( _t_ _i_ ) _,_ _F_ ˆ _i_ = ˆ _F_ ( _t_ _i_ ) _,_ _G_ ˆ _i_ = ˆ _G_ ( _t_ _i_ ) _,_ (15)\n\n\nwhere\n\n\n_̸_\n\n\n_̸_\n\n\n\n_F_ ˆ ( _t_ ) ≜\n\n\n_̸_\n\n\n_̸_\n\n\n\n_I_ ˆ _f_ _o_ ( _t_ ) _,_ _t ∈_ [ _T_ 0 + _τ_ 1 + _τ_ 2 _, ∞_ ) _,_\n(16)\n�0 _,_ _t < T_ 0 + _τ_ 1 + _τ_ 2 _,_\n\n\n_̸_\n\n\n_̸_\n\n\n\n_G_ ˆ ( _t_ ) ≜\n\n\n_̸_\n\n\n_̸_\n\n\n\n_I_ ˆ _σ_ ( _t_ ) _t_ _∈_ [ _T_ 0 + _τ_ 1 + _τ_ 2 _, ∞_ ) _,_\n(17)\n�0 _t < T_ 0 + _τ_ 1 + _τ_ 2 _,_\n\n\n_̸_\n\n\n_̸_\n\n\n\nwhere _I_ ˆ denote the operator _f_ _�→_\n_t_ _λ_\n´ _t−τ_ 2 ´ _λ−τ_ 1 _[f]_ [ (ˆ] _[x]_ [ (] _[τ]_ [)] _[, u]_ [ (] _[τ]_ [))][ d] _[τ]_ [d] _[λ]_ [ In this case, the error]\nterm _E_ _i_ is given by _E_ _i_ = _E_ ( _t_ _i_ ) + _F_ ( _t_ _i_ ) _−_ _F_ [ˆ] ( _t_ _i_ ) +\n_θ_ _[T]_ [ �] _G_ ( _t_ _i_ ) _−_ _G_ [ˆ] ( _t_ _i_ ) _ _ Let [ _t_ 1 _, t_ 2 ) be an interval over which\n�\nthe history stack was recorded Provided the states and\nthe state estimates remain within a compact set _χ_ over\n_I_ ≜ [ _t_ 1 _−_ _τ_ 1 _−_ _τ_ 2 _, t_ 2 ), the error terms can be bounded as\n\n\n_∥E_ _i_ _∥≤_ _L_ 1 ~~_ϵ_~~ + _L_ 2 _x_ ˜ _I_ _, ∀i ∈{_ 1 _, · · ·, M_ _},_ (18)\n\n\nwhere ˜ _x_ _I_ ≜ max _i∈{_ 1 _,···,M_ _}_ sup _t∈I_ _∥x_ ˜ ( _t_ ) _∥_ and _L_ 1 _, L_ 2 _>_ 0\nare constants The concurrent learning update law to estimate the unknown parameters is designed as\n\n\n_̸_\n\n\n_̸_\n\n\n\nerror bound introduced by _ϵ_ ) represent the system dynamics Hence, the history stack needs to be purged whenever better\nestimates of the state are available Since the state estimator exponentially drives the estimation error to a small neighborhood of the origin, a newer\nestimate of the state can be assumed to be at least as good\nas an older estimate A dwell time based greedy purging\nalgorithm is developed in this paper to utilize newer data for\nestimation while preserving stability of the estimator The algorithm maintains two history stacks, a main history stack and a transient history stack, labeled _H_ and _G_,\nrespectively As soon as the transient history stack is full\nand sufficient dwell time has passed, the main history stack\nis emptied and the transient history stack is copied into the\nmain history stack The sufficient dwell time, denoted by _T_,\nis determined using a Lyapunov-based stability analysis Parameter identification in the developed framework imposes the following requirement on the history stack _H_ _M_\n**Definition 1 ** _A history stack_ _P_ _i_ _,_ _F_ [ˆ] _i_ _,_ _G_ [ˆ] _i_\n�� �� _i_ =1 _[is called]_\n\n_full rank if there exists a constant c ∈_ R _such that_\n\n\n0 _< c < λ_ min _{G },_ (22)\n\n\n_where λ_ min ( _·_ ) _denotes the minimum singular value of a_\n_matrix _\n\n\n**Assumption 1 ** For a given _M ∈_ N and _c ∈_ R _>_ 0, there\nexists a set of time instances _{t_ _i_ _}_ _[M]_ _i_ =1 [such that a history]\nstack recorded using (15) is full rank A singular value maximization algorithm is used to select\nthe time instances _{t_ _i_ _}_ _[M]_ _i_ =1 [ That is, a data-point] _P_ _j_ _,_ _F_ [ˆ] _j_ _,_ _G_ [ˆ] _j_\n� �\n\nin the history stack is replaced with a new data-point\n_P_ _[∗]_ _,_ _F_ [ˆ] _[∗]_ _,_ _G_ [ˆ] _[∗]_ [�], where _F_ [ˆ] _[∗]_ = _F_ [ˆ] ( _t_ ), _P_ _[∗]_ = _P_ ( _t_ ), and _G_ [ˆ] _[∗]_ =\n�ˆ\n_G_ ( _t_ ), for some _t_, only if\n\n\n_̸_\n\n\n_̸_\n\n\n\n˙ˆ\n_θ_ ( _t_ ) = _k_ _θ_ Γ ( _t_ )\n\n\n_̸_\n\n\n_̸_\n\n\n\n_M_\n� _G_ ˆ _i_ � _P_ _i_ _−_ _F_ [ˆ] _i_ _−_ _θ_ [ˆ] _[T]_ ( _t_ ) _G_ [ˆ] _i_ � _T_ _,_ (19)\n\n_i_ =1\n\n\n_̸_\n\n\n_̸_\n\n\n\nwhere _k_ _θ_ _∈_ R _>_ 0 is a constant adaptation gain and Γ :\nR _≥_ 0 _→_ R [(] [2] _[n]_ [2] [+] _[mn]_ [)] _[×]_ [(] [2] _[n]_ [2] [+] _[mn]_ [)] is the least-squares gain\nupdated using the update law\n\n\n˙Γ ( _t_ ) = _β_ 1 Γ ( _t_ ) _−_ _k_ _θ_ Γ ( _t_ ) _G_ Γ ( _t_ ) _ _ (20)\n\n\n_̸_\n\nwhere the matrix _G ∈_ R _[p][×][p]_ is defined as _G_ ≜ [�] _[M]_ _i_ =1 _[G]_ [ˆ] _[i]_ [ ˆ] _[G]_ _i_ _[T]_ [ ]\nUsing arguments similar to [1, Corollary 4 3 2], it can be _̸_\nshown that provided _λ_ min �Γ _[−]_ [1] ( _T_ 0 )� _>_ 0, the least squares\ngain matrix satisfies\n\n\nΓ I _p_ _≤_ Γ ( _t_ ) _≤_ Γ I _p_ _,_ (21)\n\n\nwhere Γ and Γ are positive constants, and I _n_ denotes an\n_n × n_ identity matrix V P URGING\n\n\nThe update law in (19) is motivated by the fact that if the\nfull state were available for feedback and if the approxima_T_\ntion error, _ϵ_, were zero, then using � _P_ 1 _· · ·_ _P_ _n_ � =\n_T_ _T_\n� _F_ 1 _· · ·_ _F_ _n_ � + � _G_ 1 _· · ·_ _G_ _n_ � _θ,_ the parameters could be estimated via the least squares esti_T_\nmate _θ_ [ˆ] LS = _G_ _[−]_ [1] [ �] _G_ 1 _· · ·_ _G_ _n_ �� _P_ 1 _· · ·_ _P_ _n_ � _−_\n_T_\n_G_ _[−]_ [1] [ �] _G_ 1 _· · ·_ _G_ _n_ �� _F_ 1 _· · ·_ _F_ _n_ � However, since\nthe history stack contains the estimated terms _F_ [ˆ] and _G_ [ˆ],\nduring the transient period where the state estimation error\nis large, the history stack does not accurately (within the\n\n\n\n_̸_\n\n\n_̸_\n\n(23)\nwhere s min ( _·_ ) denotes the minimum singular value of a\nmatrix and _ζ_ is a constant To simplify the analysis, new\ndata points are assumed to be collected _τ_ 1 + _τ_ 2 seconds after\na purging event Since the history stack is updated using a\nsingular value maximization algorithm, the matrix _G_ is a\npiece-wise constant function of time The use of singular\nvalue maximization to update the history stack implies that\nonce the matrix _G_ satisfies (22), at some _t_ = _T_, and for\nsome _c_, the condition _c < λ_ min ( _G_ ( _t_ )) holds for all _t ≥_ _T_ The developed purging method is summarized in Fig 1",
    "1 A Lyapunov-based analysis of the parameter and the state\nestimation errors is presented in the following section A Lyapunov-based analysis of the parameter and the state\nestimation errors is presented in the following section VI S TABILITY A NALYSIS\n\n\nEach purging event represents a discontinuous change in\nthe system dynamics; hence, the resulting closed-loop system\nis a switched system To facilitate the analysis of the switched\nsystem, let _ρ_ : R _≥_ 0 _→_ N denote a switching signal such\n\n\n\n _<_ s min �� _i_ = _̸_ _j_ _[G]_ [ˆ] _[i]_ [ ˆ] _[G]_ _i_ _[T]_ [+ ˆ] _[G]_ _[∗]_ _[G]_ [ˆ] _[∗][T]_ [�]\n\n(1 + _ζ_ )\n\n_̸_ \n\n\n\n_̸_\n\n\n\n\n_̸_\n\n\n\n_̸_\n\ns min\n\n\n_̸_\n\n\n\n_̸_\n\n\n\n\n_̸_\n\n\n\n_̸_\n\n [�] _i_ = _̸_ _j_\n\n\n\nˆ _̸_\n_G_ _i_ ˆ _G_ _[T]_ _i_ [+ ˆ] _[G]_ _[j]_ _[G]_ [ˆ] _[T]_ _j_\n\n[�] _i_ = _̸_ _j_\n\n\n\n_̸_\n\n(1 + _ζ_ ) _,_\n\n_̸_\n\n\n1: _δ_ ( _T_ 0 ) _←_ 0, _η_ ( _T_ 0 ) _←_ 0\n2: **if** _t > δ_ ( _t_ ) + _τ_ 1 + _τ_ 2 and a data point is available **then**\n\n3: **if** _G_ is not full **then**\n4: add the data point to _G_\n5: **else**\n\n6: add the data point to _G_ if (23) holds\n7: **end if**\n8: **if** s min ( _G_ ) _≥_ _ξη_ ( _t_ ) **then**\n\n9: **if** _t −_ _δ_ ( _t_ ) _≥T_ ( _t_ ) **then**\n10: _H ←G_ and _G ←_ 0 _▷_ purge and replace _H_\n11: _δ_ ( _t_ ) _←_ _t_\n12: **if** _η_ ( _t_ ) _<_ s min ( _G_ ) **then**\n13: _η_ ( _t_ ) _←_ s min ( _G_ )\n14: **end if**\n\n\n15: **end if**\n\n16: **end if**\n\n17: **end if**\n\n\nFig 1 Algorithm for history stack purging with dwell time At each time\ninstance _t_, _δ_ ( _t_ ) stores the last time instance _H_ was purged, _η_ ( _t_ ) stores the\nhighest minimum singular value of _G_ encountered so far, _T_ ( _t_ ) denotes the\ndwell time, and _ξ ∈_ (0 _,_ 1] denotes a threshold fraction that _ρ_ (0) = 1, and _ρ_ ( _t_ ) = _i_ + 1, where _i_ denotes the\nnumber of times the update _H ←G_ was carried out over\nthe time interval (0 _, t_ ) For some _s ∈_ N, let _H_ _s_ denotes the\nhistory stack active during the time interval _{t | ρ_ ( _t_ ) = _s}_ ),\ncontaining the elements _P_ _si_ _,_ _F_ [ˆ] _si_ _,_ _G_ [ˆ] _si_\n�� �� _i_ =1 _,···,M_ [, and let]\n\n_E_ _si_ _[T]_ [be the corresponding error term To simplify the notation,]\nlet _G_ _s_ ≜ [�] _[M]_ _i_ =1 _[G]_ [ˆ] _[si]_ [ ˆ] _[G]_ _si_ _[T]_ [, and] _[ Q]_ _[s]_ [ =][ �] _[M]_ _i_ =1 _[G]_ [ˆ] _[si]_ _[E]_ _si_ _[T]_ [ ]\nUsing (14) and (19), the dynamics of the parameter\nestimation error can be expressed as\n\n\n˙˜\n_θ_ ( _t_ ) = _−k_ _θ_ Γ ( _t_ ) _G_ _s_ ( _t_ ) ˜ _θ_ ( _t_ ) _−_ _k_ _θ_ Γ ( _t_ ) _Q_ _s_ ( _t_ ) _ _ (24)\n\n\nSince the functions _G_ _s_ : R _≥T_ 0 _→_ R _[p][×][p]_ and _Q_ _s_ : R _≥T_ 0 _→_\nR _[p][×][n]_ are piece-wise continuous, the trajectories of (24), and\nof all the subsequent error systems involving _G_ _s_ and and _Q_ _s_,\nare defined in the sense of Carathéodory Algorithm 1 ensures\nthat there exists a constant _g >_ 0 such that _λ_ min _{G_ _s_ _} ≥_\n_g, ∀s ∈_ N Using the dynamics in (1), (9) - (11), and the design of\nthe feedback component in (12), the time-derivative of the\nerror signal _r_ is given by\n\n\n˙ ˜ ˜\n_r_ ( _t_ ) = _−kr_ ( _t_ )+ _f_ [˜] _[o]_ ( _x, u,_ ˆ _x_ )+ _θ_ _[T]_ _σ_ ( _x, u,_ ˆ _x_ ) _−θ_ [˜] _[T]_ _σ_ ( _x, u,_ ˆ _x_ )\n\n\n˜\n+ _θ_ [˜] _[T]_ _σ_ ( _x, u_ ) + _ϵ_ ( _x, u_ ) _−_ _α_ [2] _p_ + ( _k_ + _α_ ) _η,_ (25)\n\n\nwhere ˜ _σ_ ( _x, u,_ ˆ _x_ ) = _σ_ ( _x, u_ ) _−_ _σ_ (ˆ _x, u_ ) and _f_ [˜] _[o]_ ( _x, u,_ ˆ _x_ ) =\n_f_ ( _x, u_ ) _−_ _f_ (ˆ _x, u_ ) Since ( _x, u_ ) _�→_ _f_ ( _x, u_ ) and ( _x, u_ ) _�→_\n_σ_ ( _x, u_ ) are locally Lipschitz, and since _t �→_ _u_ ( _t_ ) is bounded,\ngiven a compact set ˆ _χ ⊂_ R _[n]_ _×_ R _[m]_ _×_ R _[n]_, there exist\n\n˜ ˜\n_L_ _f_ _, L_ _σ_ _>_ 0 such that˜ sup ( _x,u,x_ ˆ) _∈χ_ ˆ ��� _f_ ˜ _o_ ( _x, u,_ ˆ _x_ )��� _≤_ _L_ _f_ _∥x∥_\nand sup ( _x,u,x_ ˆ) _∈χ_ ˆ _∥σ_ ( _x, u,_ ˆ _x_ ) _∥≤_ _L_ _σ_ _∥x∥_ To facilitate the analysis, let _{T_ _s_ _∈_ R _≥_ 0 _| s ∈_ N _}_\nbe a set of switching time instances defined as _T_ _s_ =\n_{t_ _|_ _ρ_ ( _τ_ ) _< s_ + 1 _, ∀τ ∈_ [0 _, t_ ) _∧_ _ρ_ ( _τ_ ) _≥_ _s_ + 1 _, ∀τ ∈_ [ _t, ∞_ ) _} _\n\n\n\nThat is, for a given switching index _s, T_ _s_ denotes the time\ninstance when the ( _s_ + 1) [th] subsystem is switched on The\nanalysis is carried out separately over the time intervals\n\n[ _T_ _s−_ 1 _, T_ _s_ ), _s ∈_ N, where _T_ 1 = _T_ 0 + _τ_ 1 + _τ_ 2 + _t_ _M_ Since the\nhistory stack _H_ is not updated over the intervals [ _T_ _s−_ 1 _, T_ _s_ ),\n_s ∈_ N, the matrices _G_ _s_ and _Q_ _s_ are constant over each\nindividual interval The history stack that is active over the\ninterval [ _T_ _s_ _, T_ _s_ +1 ) is denoted by _H_ _s_ To ensure boundedness\nof the trajectories in the interval _t ∈_ [ _T_ 0 _, T_ 1 ), the history\nstack _H_ 1 is arbitrarily selected to be full rank The analysis is\ncarried out over the aforementioned intervals using the state\n\n\n\nvectors _Z_ ≜\n�\n\n\n\n_p_ ˜ _[T]_ _r_ _[T]_ _η_ _[T]_ vec _θ_ ˜ _T_ [�] _[T]_ _∈_ R [3] _[n]_ [+] _[np]_ and\n� �\n\n\n\n_Y_ ≜ � _p_ ˜ _[T]_ _r_ _[T]_ _η_ _[T]_ [ �] _[T]_ _∈_ R [3] _[n]_ as follows _Interval_ _1:_ First, it is established that _Z_\nis bounded over [ _T_ 0 _, T_ 1 ), where the bound is\n_O_ _∥Z_ ( _T_ 0 ) _∥_ + _Mi_ =1 _[E]_ [1] _[i]_ + ~~_ϵ_~~ Given some _ε_ _>_ 0,\n� ���� ��� �\nthe bound on _Z_ is utilized to select gains such that\n_∥Y_ ( _T_ 1 ) _∥_ _< ε_ _Interval 2:_ The history stack _H_ 2, which is active over\n\n[ _T_ 1 _, T_ 2 ), is recorded over [ _T_ 0 _, T_ 1 ) Without loss of generality,\nit is assumed that _H_ 2 represents the system better than\n_H_ 1 (which is arbitrarily selected), that is, � _Mi_ =1 _[E]_ [1] _[i]_ _≥_\n��� ���\n� _Mi_ =1 _[E]_ [2] _[i]_ The bound on _Z_ over [ _T_ 1 _, T_ 2 ) is then shown\n��� ���\nto be smaller than that over [ _T_ 0 _, T_ 1 ), which utilized to show\nthat _∥Y_ ( _t_ ) _∥≤_ _ε,_ for all _t ∈_ [ _T_ 1 _, T_ 2 ) _Interval 3:_ Using (18), the errors _E_ 3 _i_ are shown to be\n_O_ ( _∥Y_ 3 _i_ _∥_ + ~~_ϵ_~~ ~~)~~ where _Y_ 3 _i_ denotes the value of _Y_ at the\ntime when the point _P_ 3 _i_ _,_ _F_ [ˆ] 3 _i_ _,_ _G_ [ˆ] 3 _i_ was recorded Using\n� �\nthe facts that the history stack _H_ 3, which is active over\n\n[ _T_ 2 _, T_ 3 ), is recorded over [ _T_ 1 _, T_ 2 ) and _∥Y_ ( _t_ ) _∥≤_ _ε,_ for all\n_M_\n_t ∈_ [ _T_ 1 _, T_ 2 ), the error _i_ =1 _[E]_ [3] _[i]_ is shown to be _O_ ( _ε_ + ~~_ϵ_~~ ~~)~~ ���� ���\nIf _T_ 3 = _∞_ then it is established that lim sup _t→∞_ _∥Z_ ( _t_ ) _∥_ =\n_O_ ( _ε_ + ~~_ϵ_~~ ~~)~~ If _T_ 3 _< ∞_ then the fact that the bound on _Z_\nover [ _T_ 2 _, T_ 3 ) is smaller than that over [ _T_ 1 _, T_ 2 ) is utilized to\nshow that _∥Y_ ( _t_ ) _∥≤_ _ε,_ for all _t ∈_ [ _T_ 2 _, T_ 3 ) The analysis\nis then continued in an inductive argument to show that\nlim sup _t→∞_ _∥Z_ ( _t_ ) _∥_ = _O_ ( _ε_ + ~~_ϵ_~~ ~~)~~ and _∥Y_ ( _t_ ) _∥≤_ _ε,_ for all\n_t ∈_ [ _T_ 2 _, ∞_ ) The stability result is summarized in the following theo\nrem **Theorem 1 ** Let _ε >_ 0 be given Let the history stacks\n_H_ and _G_ be populated using the algorithm detailed in\nFig 1 Let the learning gains be selected to satisfy the\nsufficient gain conditions in (28), (29), (34), and (38) Let\n_T ∈_ R _>_ 0 be a time instance such that the system states\nare exciting over [ _T_ 0 _, T_ ], that is, the history stack can be\nreplenished if purged at any time _t ∈_ [ _T_ 0 _, T_ ] Assume that\nover each switching interval _{t | ρ_ ( _t_ ) = _s}_, the dwell-time,\n_T_, is selected such that _T_ ( _t_ ) = _T_ _s_, where _T_ _s_ is selected to\nbe large enough to satisfy (37) Furthermore assume that the\n\n\nexcitation interval is large enough so that _T_ 2 _< T_ [2] Then,\nlim sup _t→∞_ _∥Z_ ( _t_ ) _∥_ = _O_ ( _ε_ + ~~_ϵ_~~ ~~)~~ _Proof",
    "_Proof _ Provided _H_ 1 is full rank, then the candidate Lyapunov\nfunction\n\n2 _V_ ( _Z, t_ ) ≜ _α_ [2] _p_ ˜ _[T]_ _p_ ˜ + _r_ _[T]_ _r_ + _η_ _[T]_ _η_ + tr � _θ_ ˜ _[T]_ Γ _[−]_ [1] ( _t_ ) ˜ _θ_ � (26)\n\n\ncan be utilized to establish boundedness of trajectories over\n\n[ _T_ _s−_ 1 _, T_ _s_ ) The candidate Lyapunov function satisfies\n\n\n_v_ _∥Z∥_ [2] _≤_ _V_ ( _Z, t_ ) _≤_ ~~_v_~~ _∥Z∥_ [2] _,_ (27)\n\n\n\nIn particular, _∀t ∈_ [ _T_ 0 _, T_ 1 ) _,_\n\n\n\n_V_ ( _Z_ ( _t_ ) _, t_ ) _≤_\n�\n\n\n\n_V_ 1 _−_ ~~_[v]_~~\n\n_v_ _[ι]_ [1]\n\n\n\n_V_ 1 _−_ ~~_[v]_~~\n\n\n\ne _[−]_ _[v]_ ~~_v_~~\n�\n\n\n\n\n_[v]_ ~~_v_~~ [(] _[t][−][T]_ [0] [)] + ~~_[v]_~~\n\n\n\n_v_ _[ι]_ [1] _[,]_ (30)\n\n\n\n��\n\n\n\n�\n\n\n\n~~�~~\n\n\n\n~~_v_~~\n_v_ _[ι]_ [1]\n\n\n\n_v_ [max]\n\n\n\n_V_ 1 _,_\n\n\n\n_ _ (31)\n\n\n\nwhere ~~_v_~~ ≜ [1]\n\n\n\nwhere ~~_v_~~ ≜ [1] 2 [max] �1 _, α_ [2] _,_ [1] _/_ Γ � and _v_ ≜ [1] 2 [min] �1 _, α_ [2] _,_ [1] ~~_/_~~ Γ � The time-derivative of _V_ along the trajectories of (10), (11),\n(20), (24), and (25) is given by\n\n_V_ ˙ = _−α_ [3] _p_ ˜ _[T]_ _p_ ˜ _−_ _kr_ _[T]_ _r −_ _βη_ _[T]_ _η −_ [1] _θ_ ˜ _[T]_ [�] _k_ _θ_ _G_ 1 + _β_ 1 Γ _[−]_ [1] [�] _θ_ [˜]\n\n2 [tr] � �\n\n\n\n\n[1] 2 [max] �1 _, α_ [2] _,_ [1] _/_ Γ\n\n\n\nand _v_ ≜ [1]\n� 2\n\n\n\nIf it were possible to use the inequality in (30) to conclude\nthat over [ _T_ 0 _, T_ 1 ), _V_ ( _Z_ ( _t_ ) _, t_ ) _≤_ _V_ ( _Z_ ( _T_ 0 ) _, T_ 0 ), then an\ninductive argument could be used to show that the trajectories\ndecay to a neighborhood of the origin However, unless\nthe history stack can be selected to have arbitrarily large\nminimum singular value (which is generally not possible),\nthe constant ~~_[v]_~~ _[ι]_\n\n\n\n_V_ ˙ = _−α_ [3] _p_ ˜ _[T]_ _p_ ˜ _−_ _kr_ _[T]_ _r −_ _βη_ _[T]_ _η −_ [1]\n\n\n\n+ _r_ _[T]_ [ ˜] _f_ _[o]_ + _r_ _[T]_ _θ_ _[T]_ _σ_ ˜ + _r_ _[T]_ [ ˜] _θ_ _[T]_ _σ_ ˆ + _r_ _[T]_ _ϵ −_ _k_ _θ_ tr _θ_ ˜ _[T]_ _Q_ _s_ _ _\n� �\n\n\nUsing the Cauchy-Schwartz inequality, the derivative can be\nbounded as\n\n\n\nwhere _V_ 1 _>_ 0 is a constant such that _|V_ ( _Z_ ( _T_ 0 ) _, T_ 0 ) _| ≤_ _V_ 1 Hence, _∀t ∈_ [ _T_ 0 _, T_ 1 ) _,_\n\n˜ 1 ~~_v_~~\n_θ_ ( _t_ ) _≤_ _θ_ 1 ≜ _V_ 1 _,_ _ _ (31)\n��� ��� � _v_ [max] �� ~~�~~ _v_ _[ι]_ [1] �\n\n\nIf it were possible to use the inequality in (30) to conclude\nthat over [ _T_ 0 _, T_ 1 ), _V_ ( _Z_ ( _t_ ) _, t_ ) _≤_ _V_ ( _Z_ ( _T_ 0 ) _, T_ 0 ), then an\ninductive argument could be used to show that the trajectories\ndecay to a neighborhood of the origin However, unless\nthe history stack can be selected to have arbitrarily large\nminimum singular value (which is generally not possible),\nthe constant ~~_[v]_~~\n\n_v_ _[ι]_ [1] [ cannot be made arbitrarily small using the]\nlearning gains Since _ι_ _s_ depends on _Q_ _s_, it can be made smaller by\nreducing the estimation errors and thereby reducing the errors\nassociated with the data stored in the history stack To that\nend, consider the candidate Lyapunov function\n\n\n\n˙ ˜\n_V ≤−α_ [3] _∥p∥_ [2] _−_ _k ∥r∥_ [2] _−_ _β ∥η∥_ [2] _−_ [1]\n\n2 _[a]_\n\n\n\n_θ_ ˜ 2 + _L_ _f_ _∥r∥∥x_ ˜ _∥_\n��� ���\n\n\n\n2 _[r]_ _[T]_ _[ r]_ [ + 1] 2\n\n\n\n(32)\n2 _[η]_ _[T]_ _[ η ]_\n\n\n\n+ _∥r∥_ _θL_ _σ_ _∥x_ ˜ _∥_ + _∥r∥_ _θ_ ˜ _∥σ_ ˆ _∥_ + _∥r∥_ ~~_ϵ_~~ + _k_ _θ_ _θ_ ˜ _Q_ _s_ _,_\n��� ��� ��� ���\n\nwhere _a_ = _k_ _θ_ _g_ + _[β]_ Γ [1] _[,]_ [ and] _[ Q]_ _[s]_ [ is a positive constant such that]\n\n_Q_ _s_ _≥∥Q_ _s_ _∥_ Provided\n\n\n\n_W_ ( _Y_ ) ≜ _[α]_ [2]\n\n\n\n2 _[p]_ [˜] _[T]_ [ ˜] _[p]_ [ + 1] 2\n\n\n\n_k >_ max 2 (4 + _α_ ) � _L_ _f_ + _θL_ _σ_ � _,_ [1] ~~[2]~~ ~~_[σ]_~~ [2]\n� _a_\n\n_α_ [3] _>_ (1 + _α_ ) � _L_ _f_ + _θL_ _σ_ � _,_\n\n\n\n_,_\n�\n\n\n\n_β >_ � _L_ _f_ + _θL_ _σ_ � _,_ (28)\n\n\nYoung’s inequality and nonlinear damping can be used to\nconclude that\n\n\n\nThe candidate Lyapunov function satisfies\n\n\n_w_ _∥Y ∥_ [2] _≤_ _W_ ( _Y, t_ ) _≤_ ~~_w_~~ _∥Y ∥_ [2] _,_ (33)\n\n\nwhere ~~_w_~~ ≜ 12 [max] �1 _, α_ [2] [�], _w_ ≜ 12 [min] �1 _, α_ [2] [�] In the\ninterval [ _T_ _s−_ 1 _, T_ _s_ ), the time-derivative of _W_ is given by\n\n\n˙ ˜ ˜ ˜ ˜\n_W_ = _−α_ [3] _p_ _[T]_ _p_ _−_ _kr_ _[T]_ _r_ _−_ _βη_ _[T]_ _η_ + _r_ _[T]_ [ �] _f_ _o_ + _θ_ _[T]_ _−_ _θ_ [˜] _[T]_ [ �] _σ_\n� �\n\n+ _r_ _[T]_ [ �] _θ_ ˜ _[T]_ _σ_ + _ϵ_\n�\n\n\nUsing the Cauchy-Schwartz inequality, the derivative _W_ [˙] can\nbe bounded as\n\n\n˙ ˜\n_W_ = _−_ _α_ [3] _∥p∥_ [2] _−_ _k ∥r∥_ [2] _−_ _β ∥η∥_ [2]\n\n\n\n_V_ ˙ _≤−_ _[α]_ [3]\n\n\n\n\n_[k]_\n\n4 _[∥][r][∥]_ [2] _[ −]_ _[β]_ 2\n\n\n\n6\n\n\n\n2 _[∥][p]_ [˜] _[∥]_ [2] _[ −]_ _[k]_ 4\n\n\n\n2 _[∥][η][∥]_ [2] _[ −]_ _[a]_ 6\n\n\n\n_θ_ ˜ 2\n��� ���\n\n\n\n+ � _L_ _f_ + �\n\n\n\n_k_\n_−_ � 8\n\n\n\n\n_[L]_ _[σ]_ _∥r∥_ [2] + ~~_[ϵ]_~~ ~~[2]~~\n\n2 _a_ _[∥][x]_ [˜] _[∥]_ [2] � _k_\n\n\n\n_k_\n\n8 _[−]_ [3] 2 _[L]_ _a_ _[σ]_\n\n\n\n\n~~[2]~~ _θ_ ~~2~~\n\n\n_s_ _[,]_\n_k_ [+ 3] 2 _[k]_ _a_ [2] _[Q]_\n\n\n\n_θ_ + _θ_ _s_ � _L_ _σ_ � _∥r∥∥x_ ˜ _∥_ + ( _θ_ _s_ ~~_σ_~~ + ~~_ϵ_~~ ~~)~~ _∥r∥_ _,_\n\n\n\nSince _∥x_ ˜ _∥_ [2] _≤_ (1 + _α_ ) _∥Z∥_ [2], _V_ [˙] _≤−ν_ � _∥Z∥−_ _[ι]_ _ν_ _[s]_ �, in the\n\ndomain\n\n\n\nwhere _θ_ _s_ _>_ 0 is a constant such that _θ_ _s_ _≥_\nsup _t∈_ [ _T_ _s−_ 1 _,T_ _s_ ) ��� _θ_ ˜ ( _t_ )��� Consider the time interval [ _T_ 0 _, T_ 1 ) Provided\n\n\n\n�\n\n\n\n~~�~~\n\n\n\n_D_ ≜\n\n\n\n_Z ∈_ R [3] _[n]_ [+] _[np]_ _| ∥Z∥_ _<_\n\n�\n\n\n\n_ka_\n\n12 _L_ _σ_ (1 + _α_ )\n\n\n\n_ _\n\n\n\n_k ≥_ 1 + _θ_ 1 [2] [+] � _L_ _f_ + � _θ_ + _θ_ 1 � _L_ _σ_ � (4 + _α_ )\n\n\n\n_θ_ + _θ_ 1 � _L_ _σ_ �\n\n\n\nThat is, _V_ [˙] is negative definite on _D_ provided _∥Z∥_ _>_ ~~[�]~~ ~~_[ι]_~~ _ν_ _[s]_\n\n\n\n\n_[s]_\n\n_ν_ _[>]_\n\n\n\n_α_ [3] _≥_ (1 + _α_ ) � _L_ _f_ + �\n\n\n\n_β ≥_ � _L_ _f_ + �\n\n\n\n_θ_ + _θ_ 1 � _L_ _σ_ � (34)\n\n\n\n~~2~~\n\n0, where _v_ ≜ 2 [1] [min] � _α_ [3] _,_ _[k]_ _/_ 2 _, β,_ _[a]_ ~~_/_~~ 3 � and _ι_ _s_ ≜ ~~_[ϵ]_~~ _k_ ~~[2]~~ [+] [ 3] 2 _[k]_ _a_ _θ_ [2] _[Q]_ _s_ [ ]\n\nTheorem 4 18 from [22] can then be invoked to co ~~nc~~ lude\nthat provided\n\n\n\nthen _W ≤−_ _[w]_ ~~_w_~~ _[W]_ [ +] _[ λ,]_ [ where] _[ w]_ [ =] 21 [min] � _α_ [3] _, k, β_ � and\n\n_λ_ = ~~_[σ]_~~ ~~[2]~~ ~~[+]~~ ~~_[ϵ]_~~ ~~[2]~~ That is, for all _t ∈_ _T_\n\n\n\n\n~~[+]~~ 2 ~~_[ϵ]_~~ That is, for all _t ∈_ [ _T_ 0 _, T_ 1 ) _,_\n\n\n\n2 [1] [min] � _α_ [3] _,_ _[k]_ _/_ 2 _, β,_ _[a]_ ~~_/_~~ 3 � and _ι_ _s_ ≜ ~~_[ϵ]_~~ _k_ ~~[2]~~\n\n\n\n0, where _v_ ≜ [1]\n\n\n\nthen _W_ ˙ _≤−_ _[w]_\n\n\n\n_k >_ [15] _[L]_ _[σ]_ [(][1 +] _[ α]_ [)] max\n\n_av_ �\n\n\n\n_W_ ( _Y_ ( _t_ ) _, t_ ) _≤_\n�\n\n\n\n_V_ _s_ _,_ ~~_[v]_~~ _[ι]_ [1]\n\n_v_\n\n\n\n_,_ (29)\n�\n\n\n\n\n~~_[w]_~~ e _[−]_ ~~_w_~~ _[w]_\n\n_w_ _[λ]_ �\n\n\n\n_W_ 1 _−_ ~~_[w]_~~\n\n\n\n\n_[w]_ ~~_w_~~ [(] _[t][−][T]_ [0] [)] + ~~_[w]_~~\n\n\n\n(35)\n_w_ _[λ,]_\n\n\n\nwhere _V_ _s_ _≥∥V_ ( _Z_ ( _T_ _s−_ 1 ) _, T_ _s−_ 1 ) _∥_ is a constant, then _V_ [˙] _≤_\n\n_−_ _[v]_\n\n~~_v_~~ _[V]_ [ +] _[ ι]_ _[s]_ _[,][ ∀][t][ ∈]_ [[] _[T]_ _[s][−]_ [1] _[, T]_ _[s]_ [)][ ]\n\n\n2 A minimum of two purges are required to remove the randomly\ninitialized data, and the data recorded during transient phase of the derivative\nestimator from the history stack where _W_ 1 _>_ 0 is a constant such that _|W_ ( _Y_ ( _T_ 0 )) _| ≤_ _W_ 1 In particular, _∀t ∈_ [ _T_ 0 _, T_ 1 ) _ _\n\n\n\n\n~~_[w]_~~ ≜ _∥Y ∥_ 1 _ _ (36)\n\n_w_ _[λ]_ ~~�~~\n\n\n\n_∥Y_ ( _t_ ) _∥≤_\n\n\n\n�\n\n\n\n1\n_w_ [max] ~~�~~\n\n\n\n_W_ 1 _,_ ~~_[w]_~~ ≜ _∥Y ∥_ 1 _ _ (36)\n\n_w_ _[λ]_ ~~�~~\n\n\nProvided the dwell time _T_ _s_ is large enough so that\n\n\n_W_ _s_ _−_ ~~_[w]_~~ _e_ _[−]_ _[w]_ ~~_w_~~ _[T]_ _[s]_ _≤_ ~~_[w]_~~\n\n� _w_ _[λ]_ � _w_ _[λ,]_\n\n\n_̸_\n\n\n\n\n~~_[w]_~~ _e_ _[−]_ _[w]_ ~~_w_~~\n\n_w_ _[λ]_ �\n\n\n_̸_\n\n\n\n_W_ _s_ _−_ ~~_[w]_~~\n\n\n_̸_\n\n\n\n\n_[w]_ ~~_w_~~ _[T]_ _[s]_ _≤_ ~~_[w]_~~\n\n\n_̸_\n\n\n\n_W_ _s_ _−_ _e_ _[−]_ ~~_w_~~ _[s]_ _≤_\n\n_w_ _[λ]_ _w_ _[λ,]_\n\n� _V_ _s_ _−_ ~~_[v]_~~ _v_ _[ι]_ _[s]_ � _e_ _[−]_ ~~_v_~~ _[v]_ _[T]_ _[s]_ _≤_ ~~_[v]_~~ _v_ _[ι]_ _[s]_ _[,]_\n\n\n_̸_\n\n\n\n_V_ _s_ _−_ ~~_[v]_~~\n\n\n_̸_\n\n\n\n_v_ _[ι]_ _[s]_\n\n\n_̸_\n\n\n\n_e_ _[−]_ ~~_v_~~ _[v]_\n�\n\n\n_̸_\n\n\n\n~~_v_~~ _[v]_ _[T]_ _[s]_ _≤_ ~~_[v]_~~\n\n\n_̸_\n\n\n\n_v_ _[ι]_ _[s]_ _[,]_ (37)\n\n\n_̸_\n\n\n\nthen from (30) and (35), _W_ ( _Y_ ( _T_ 1 )) _≤_ ~~2~~ ~~_wλ_~~ _w_ and\n\n\n_̸_\n\n\n\n~~_vι_~~ _v_ 1 [ In particular,] _[ ∥][Y]_ [ (] _[T]_ [1] [)] _[∥≤]_\n\n~~�~~\n\n\n_̸_\n\n\n\nTABLE I\n\nS IMULATION PARAMETERS FOR THE DIFFERENT SIMULATION RUNS T HE PARAMETERS ARE SELECTED USING TRIAL AND ERROR Noise Variance\n\nParameter 0 0 001\n\n\n_T_ 1 0 5 0 9\n_T_ 2 0 3 0 5\n_N_ 50 150\nΓ ( _t_ 0 ) I 4 I 4\n_β_ 1 0 5 0 5\n_α_ 2 2\n\n_k_ 10 10\n_β_ 2 2\n_ζ_ 0 0\n_ξ_ 0 95 0 95\n_k_ _θ_ 0 5 / N 0 5 / N\n\n\n10\n\n\n8\n\n\n6\n\n\n4\n\n\n2\n\n\n0\n\n\n-2\n\n_̸_\n\n\n0 10 20 30 40 50\n\nTime (s)\n\n_̸_\n\n\n\nFig 2",
    "2 Trajectories of the parameter estimation errors using noise-free\nposition measurements _̸_\n\n\n\n_V_ ( _Z_ ( _T_ 1 ) _, T_ 1 ) _≤_ ~~2~~ ~~_vι_~~ 1\n\n\n_̸_\n\n\n\n~~2~~ ~~_wλ_~~\n\n\n_̸_\n\n\n\n_v_ _ww_\n\n\nand _∥Z_ ( _T_ 1 ) _∥≤_ ~~2~~ _vv_ ~~_vι_~~ 1 [ Note that the bound on] _[ Y]_ [ (] _[T]_ [1] [)][ can]\n�\n\n\n_̸_\n\n\n\n~~2~~ ~~_vι_~~ 1\n\n\n_̸_\n\n\n\nand _∥Z_ ( _T_ 1 ) _∥≤_ _vv_ ~~_vι_~~ 1 [ Note that the bound on] _[ Y]_ [ (] _[T]_ [1] [)][ can]\n\nbe made arbitrarily small by increasing _k, α,_ and _β_ Now the interval [ _T_ 1 _, T_ 2 ) is considered Since the history\nstack _H_ 2 which is active during [ _T_ 1 _, T_ 2 ) is recorded during\n\n[ _T_ 0 _, T_ 1 ), the bound in (18) can be used to show that _Q_ 2 =\n_O_ _∥Y ∥_ 1 + ~~_ϵ_~~ � �\n\nSince _H_ 1 is independent of the system trajectories, _Q_ 1\ncan be selected such that _Q_ 2 _< Q_ 1, and hence, _ι_ 2 _< ι_ 1 Thus, provided the constant _V_ 1 (and as a result, the gain _k_ )\nis selected large enough so that\n\n\n_̸_\n\n\n\n_∥Y ∥_ 1 + ~~_ϵ_~~ �\n\n\n_̸_\n\n\n\n~~2~~ ~~_v_~~ _ι_ 1\n\n_< V_ 1 _,_ (38)\n_v_\n\n\n_̸_\n\n\n\nthe gain condition in (29) holds over [ _T_ 1 _, T_ 2 ), and hence, a\nsimilar Lyapunov-based analysis, along with the bound _V_ 2 =\n~~2~~ ~~_vι_~~ 1\n\n\n_̸_\n\n\n\n~~_vι_~~ _v_ 1 can be utilized to conclude that _∀t ∈_ [ _T_ 1 _, T_ 2 ),\n\n\n_θ_ ˜ ( _t_ ) _≤_ ~~_v_~~ � _√_ 2 _ι_ 1 _,_ _[√]_ ~~_ι_~~ 2 � ≜ _θ_ 2 _ _\n��� ��� ~~�~~ _vv_ [max]\n\n\n_̸_\n\n\n\n� _√_\n_vv_ [max]\n\n\n_̸_\n\n\n\n2 _ι_ 1 _,_ _[√]_ ~~_ι_~~ 2 � ≜ _θ_ 2 _ _ (39)\n\n\n_̸_\n\n\n\nThe sufficient condition in (38) implies that _V_ 2 _< V_ 1 and\nhence, (31) and _ι_ 2 _< ι_ 1 imply that _θ_ 2 _< θ_ 1 Since _θ_ 2 _< θ_ 1, the gain conditions in (34) hold over\nthe interval [ _T_ 1 _, T_ 2 ) A Lyapunov-based analysis similar to\n(32)-(36) yields _∥Y_ ( _t_ ) _∥≤_ _w_ 1 [max] ~~�~~ _W_ 2 _,_ ~~_[w]_~~ _w_ _[λ]_ ~~�~~ _ _ From (37),\n�\n\n\n_̸_\n\n\n\n_Q_ 3 = _O_\n�\n\n\n_̸_\n\n\n\n1\n_w_ [max] ~~�~~\n\n\n_̸_\n\n\n\n\n~~_[w]_~~ _w_ _[λ]_ ~~�~~ _ _ From (37),\n\n\n_̸_\n\n\n\n_W_ 2 _,_ ~~_[w]_~~\n\n\n_̸_\n\n\n\n~~_ϵ_~~ ~~[2]~~\n_∥Y ∥_ 2 + ~~_ϵ_~~ � and _ι_ 3 = _k_\n\n\n_̸_\n\n\n\n_W_ 2 = ~~[2]~~ ~~_[wλ]_~~ _w_ [, and hence,] _[ ∀][t][ ∈]_ [[] _[T]_ [1] _[, T]_ [2] [)][,]\n\n\n_̸_\n\n\n\n_Q_ 3 = _O_ � _∥Y ∥_ 2 + ~~_ϵ_~~ � and _ι_ 3 = ~~_ϵ_~~ _k_ ~~[2]~~ [+] [ 3] 2 _[k]_ _a_ _θ_ [2] _[Q]_ ~~2~~ 3 [implies that]\n\nlim sup _t→∞_ _∥Z_ ( _t_ ) _∥_ = _O_ ( _ε_ + ~~_ϵ_~~ ~~)~~ If _T_ 3 = _̸_ _∞_ then an inductive continuation of the\nLyapunov-based analysis to the time intervals [ _T_ _s−_ 1 _, T_ _s_ )\nshows that provided the dwell time _T_ _s_ satisfies (37), the gain\nconditions in (28), (29), and (34) are satisfied for all _t > T_ 3,\nthe state _Y_ satisfies\n\n\n\n_∥Y_ ( _t_ ) _∥≤_ _̸_\n\n\n\n_̸_\n\n~~�~~\n\n\n\n~~2~~ ~~_w_~~ _λ_\n\n_ww_ [≜] _[∥][Y][ ∥]_ [2] _[ ]_ (40) _̸_\n\n\n\n_̸_\n\n\nNow, the interval [ _T_ 2 _, T_ 3 ) is considered Since the history\nstack _H_ 3 which is active during [ _T_ 2 _, T_ 3 ) is recorded during\n\n[ _T_ 1 _, T_ 2 ), the bounds in (18) and (40) can be used to show\nthat _Q_ 3 = _O_ _∥Y ∥_ 2 + ~~_ϵ_~~ _ _ By selecting _W_ 1 large enough,\n� �\n\nit can be ensured that _∥Y ∥_ 2 _< ∥Y ∥_ 1, and hence, _Q_ 3 _< Q_ 2,\nwhich implies _ι_ 3 _< ι_ 2 Provided _T_ 2 satisfies (37), then\n� _V_ 2 _−_ ~~_[v]_~~ _v_ _[ι]_ [2] � _e_ _[−]_ _[v]_ ~~_v_~~ [(] _[T]_ [2] _[−][T]_ [1] [)] _≤_ ~~_v_~~ _v_ _[ι]_ [2] [, which implies] _[ V]_ [ 3] [ =] ~~_v_~~ _v_ _[ι]_ [2] [,]\n\n\n\n_̸_\n\n\n� _V_ 2 _−_ ~~_[v]_~~ _v_ _[ι]_ [2] � _e_ _[−]_ _[v]_ ~~_v_~~ [(] _[T]_ [2] _[−][T]_ [1] [)] _≤_ ~~_v_~~ _v_ _[ι]_ [2] [, which implies] _[ V]_ [ 3] [ =] ~~_v_~~ _v_ _[ι]_ [2] [,]\n\nand hence, _V_ 3 _< V_ 2 and _θ_ 3 _< θ_ 2 Therefore, the gain\nconditions in (28), (29), and (34) are satisfied over [ _T_ 2 _, T_ 3 ) Since the gain conditions are satisfied, a Lyapunov-based\nanalysis similar to (32)-(36) yields _∥Y_ ( _t_ ) _∥≤_ ~~2~~ _w_ ~~_wλ_~~ _w_ _[,][ ∀][t][ ∈]_\n~~�~~\n\n\n\n_̸_\n\n\n_∥Y_ ( _t_ ) _∥≤_ _ε, ∀t > T_ 1 _,_ (41)\n\n\nand _Q_ _s_ _≤_ _Q_ _s−_ 1, _ι_ _s_ _≤_ _ι_ _s−_ 1, _V_ _s_ _≤_ _V_ _s−_ 1, and _θ_ _s_ _≤_ _θ_ _s−_ 1,\nfor all _s >_ 3 The bound in (41) and the fact that _Q_ _s_ =\n_O_ _∥Y ∥_ _s−_ 1 + ~~_ϵ_~~ indicate that _Q_ _s_ = _O_ ( _ε_ + ~~_ϵ_~~ ~~)~~ _, ∀s ∈_ N � �\n\n\n\n_̸_\n\n\n~~_[v]_~~ _v_ _[ι]_ [2] � _e_ _[−]_ _[v]_ ~~_v_~~\n\n\n\n_̸_\n\n\n_V_ 2 _−_ ~~_[v]_~~\n\n\n\n_̸_\n\n\nFurthermore, _V_ ( _Z_ ( _t_ ) _, t_ ) _≤_ �\n\n\n\n_̸_\n\n\n~~_[v]_~~ _v_ _[ι]_ _[s]_ � e _[−]_ ~~_v_~~ _[v]_\n\n\n\n_̸_\n\n\n_V_ _s_ _−_ ~~_[v]_~~\n\n\n\n_̸_\n\n\n~~_v_~~ _[v]_ [(] _[t][−][T]_ _[s][−]_ [1] [)] + ~~_[v]_~~\n\n\n\n_̸_\n\n\n~~2~~ ~~_wλ_~~\n\n\n\n_̸_\n\n\nanalysis similar to (32)-(36) yields _∥Y_ ( _t_ ) _∥≤_ _ww_ _[,][ ∀][t][ ∈]_\n\n[ _T_ 2 _, T_ 3 ) Given any _ε_ _>_ 0 _,_ the gains _α,_ _β,_ and _k_\ncan be selected large enough to satisfy _∥Y ∥_ 2 _≤_ _ε,_\nand hence, _∥Y_ ( _t_ ) _∥_ _≤_ _ε, ∀t_ _∈_ [ _T_ 2 _, T_ 3 ) _ _ Furthermore,\na similar Lyapunov-based analysis as (26) - (30) yields\n_V_ ( _Z_ ( _t_ ) _, t_ ) _≤_ � _V_ 3 _−_ ~~_[v]_~~ _v_ _[ι]_ [3] � e _[−]_ ~~_v_~~ _[v]_ [(] _[t][−][T]_ [2] [)] + ~~_[v]_~~ _v_ _[ι]_ [3] _[,][ ∀][t][ ∈]_ [[] _[T]_ [2] _[, T]_ [3] [)][ If]\n\n\n\n_̸_\n\n\n~~_[v]_~~ _v_ _[ι]_ [3] � e _[−]_ ~~_v_~~ _[v]_\n\n\n\n_̸_\n\n\n_V_ ( _Z_ ( _t_ ) _, t_ ) _≤_ � _V_ 3 _−_ ~~_[v]_~~ _v_ _[ι]_ [3] � e _[−]_ ~~_v_~~ [(] _[t][−][T]_ [2] [)] + ~~_[v]_~~ _v_ _[ι]_ [3] _[,][ ∀][t][ ∈]_ [[] _[T]_ [2] _[, T]_ [3] [)][ If]\n\n_T_ 3 = _∞_ then lim sup _t→∞_ _V_ ( _Z_ ( _t_ ) _, t_ ) _≤_ ~~_[v]_~~ _[ι]_ [3] [, which, from]\n\n\n\n_̸_\n\n\n_V_ 3 _−_ ~~_[v]_~~\n\n\n\n_̸_\n\n\n_[v]_ ~~_v_~~ [(] _[t][−][T]_ [2] [)] + ~~_[v]_~~\n\n\n\n_̸_\n\n\n~~_[v]_~~ _v_ _[ι]_ [3] [, which, from]\n\n\n\n_̸_\n\n\n_s_ _−_ _v_ _[ι]_ _[s]_ e ~~_v_~~ _[s][−]_ _v_ _[ι]_ _[s]_ [,]\n\n_∀t ∈_ [ _T_ _s−_ 1 _, T_ _s_ ), _∀s ∈_ N, which, along with the dwell time\nrequirement, implies that lim sup _t→∞_ _V_ ( _Z_ ( _t_ ) _, t_ ) _≤_ ~~_v_~~ _v_ _[ι]_ _[s]_ [,]\nand hence, lim sup _t→∞_ _∥Z_ ( _t_ ) _∥_ = _O_ ( _ε_ + ~~_ϵ_~~ ~~)~~ VII",
    "VII S IMULATION\n\n\nThe developed technique is simulated using a model for\na two-link robot manipulator arm S IMULATION\n\n\nThe developed technique is simulated using a model for\na two-link robot manipulator arm The uncertainty _g_ ( _x, u_ )\nis linearly parameterizable as _g_ _[T]_ ( _x, u_ ) = _θ_ _[T]_ _σ_ ( _x, u_ ) _ _ That\n\n\n1 5\n\n\n1\n\n\n0 5\n\n\n0\n\n\n-0 5\n\n\n-1\n\n\n-1 5\n\n\n-2\n\n0 10 20 30 40 50\n\nTime (s)\n\n\nFig 3 3 Trajectories of the generalized position estimation errors using\nnoise-free position measurements 6\n\n\n4\n\n\n2\n\n\n0\n\n\n-2\n\n\n-4\n\n\n-6\n\n\n-8\n\n0 10 20 30 40 50\n\nTime (s)\n\n\nFig 4 4 Trajectories of the generalized velocity estimation errors using\nnoise-free position measurements 10\n\n\n5\n\n\n0\n\n\n-5\n\n0 10 20 30 40 50\n\nTime (s)\n\n\nFig 5 Trajectories of the parameter estimation errors with a Gaussian\nmeasurement noise (variance = 0 001) _p_ 1 + 2 _a_ 3 c 2 ( _p_ ) _,_ _a_ 2 + _a_ 3 c 2 ( _p_ ) _,_ and _V_ _m_ ( _p, q_ ) ≜\n� _a_ 2 + _a_ 3 c 2 ( _p_ ) _,_ _a_ 2 �\n\n_−a_ 3 s 2 ( _p_ ) _q_ 2 _,_ _−a_ 3 s 2 ( _p_ ) ( _q_ 1 + _q_ 2 ) _,_ where c 2 ( _p_ ) =\n� _a_ 3 s 2 ( _p_ ) _q_ 1 _,_ 0 �\n\ncos ( _p_ 2 ) _,_ s 2 ( _p_ ) = sin ( _p_ 2 ), and _a_ 1 = 3 _ _ 473, _a_ 2 = 0 _ _ 196,\nand _a_ 3 = 0 _ _ 242 are constants The system has four unknown\n\n\n\n1\n\n\n0 5\n\n\n0\n\n\n-0 5\n\n\n-1\n\n\n-1 5\n\n\n-2\n\n\n-2 5\n\n\n\n0 10 20 30 40 50\n\nTime (s)\n\n\nFig 6",
    "6 Trajectories of the generalized position estimation errors with a\nGaussian measurement noise (variance = 0 001) 6\n\n\n4\n\n\n2\n\n\n0\n\n\n-2\n\n\n-4\n\n\n-6\n\n\n-8\n\n0 10 20 30 40 50\n\nTime (s)\n\n\nFig 7 7 Trajectories of the generalized velocity estimation errors with a\nGaussian measurement noise (variance = 0 001) is, the selected model belongs to a sub-class of systems\ndefined by (1), where the function approximation error, _ε_,\nis zero Since the ideal parameters, _θ_, are uniquely known,\nthe selected model facilitates quantitative analysis of the\nparameter estimation error The dynamics of the arm are\ndescribed by (1), where\n\n\n_f_ [0] ( _x, u_ ) = _−_ ( _M_ ( _p_ )) _[−]_ [1] _V_ _m_ ( _p, q_ ) _q_ + ( _M_ ( _p_ )) _[−]_ [1] _u,_\n\n\n_T_\n_g_ _[T]_ ( _x, u_ ) = _θ_ _[T]_ [ ��] ( _M_ ( _p_ )) _[−]_ [1] ( _M_ ( _p_ )) _[−]_ [1] [ �] _D_ ( _q_ )� _ _\n(42)\n\n\nIn (42), _u_ _∈_ R [2] is the control input,\n_D_ ( _q_ ) ≜ diag [tanh ( _q_ 1 ) _,_ tanh ( _q_ 2 )], _M_ ( _p_ ) ≜\n_p_ 1 + 2 _a_ 3 c 2 ( _p_ ) _,_ _a_ 2 + _a_ 3 c 2 ( _p_ ) _,_ and _V_ _m_ ( _p, q_ ) ≜\n� _a_ 2 + _a_ 3 c 2 ( _p_ ) _,_ _a_ 2 �\n\n\n\n_,_ where c 2 ( _p_ ) =\n�\n\n\nparameters The ideal values of the unknown parameters are\n_θ_ = �5 _ _ 3 1 _ _ 1 8 _ _ 45 2 _ _ 35 [�] _[T]_ _ _\nThe contribution of this paper is the design of a parameter\nestimator and a velocity observer The controller is assumed\nto be any controller that results in bounded system response In this simulation study, the controller, _u_, is designed so that\nthe system tracks the trajectory _p_ 1 ( _t_ ) = _p_ 2 ( _t_ ) = sin (3 _t_ ) +\nsin (2 _t_ ) The simulation is performed using Euler forward numerical integration using a sample time of _T_ _s_ = 0 _ _ 0005\nseconds Past _τ_ 1 _T_ + _s_ _τ_ 2 values of the generalized position, _p_,\n\nand the control input, _u_, are stored in a buffer The matrices\n_P_, _G_ [ˆ], and _F_ [ˆ] for the parameter update law in (19) are\ncomputed using trapezoidal integration of the data stored\nin the aforementioned buffer Values of _P_, _G_ [ˆ], and _F_ [ˆ] are\nstored in the history stack and are updated according to the\nalgorithm detailed in Fig 1 The initial estimates of the unknown parameters are selected to be zero, and the history stack is initialized so that all\nthe elements of the history stack are zero Data is added to the\nhistory stack using a singular value maximization algorithm To demonstrate the utility of the developed method, three\nsimulation runs are performed In the first run, the observer\nis assumed to have access to noise free measurements of the\n\ngeneralized position In the second run, a zero-mean Gaussian noise with variance 0 001 is added to the generalized\nposition signal to simulate measurement noise The values of\nvarious simulation parameters selected for the three runs are\nprovided in Table I Figure 2 demonstrates that in absence\nof noise, the developed parameter estimator drives the state\nestimation error, ˜ _x_, and the parameter estimation error, _θ_ [˜],\nclose to the origin Figures 5 - 7 indicate that the developed\ntechnique can be utilized in the presence of measurement\nnoise, with expected degradation of performance",
    "Figures 5 - 7 indicate that the developed\ntechnique can be utilized in the presence of measurement\nnoise, with expected degradation of performance VIII C ONCLUSION\n\n\nThis paper develops a concurrent learning based adaptive\nobserver and parameter estimator to simultaneously estimate\nthe unknown parameters and the generalized velocity of\nsecond-order nonlinear systems using generalized position\nmeasurements The developed technique utilizes a dynamic\nvelocity observer to generate state estimates necessary for\ndata-driven adaptation A purging algorithm is developed to\nimprove the quality of the stored data as the state estimates\nconverge to the true state By integrating _n−_ times, the\ndeveloped method can be generalized to higher-order linear\n\nsystems Simulation results indicate that the developed method is\nrobust to measurement noise A theoretical analysis of the\ndeveloped method under measurement noise and process\nnoise is a subject for future research Future efforts will\nalso focus on the examination the effect of the integration\nintervals, _τ_ 1 and _τ_ 2, on the performance of the developed\nestimator R EFERENCES\n\n\n[1] P Ioannou and J Sun, _Robust Adaptive Control_ Prentice Hall, 1996 [2] S Sastry and M Sastry and M Bodson, _Adaptive Control: Stability, Convergence,_\n_and Robustness_ Upper Saddle River, NJ: Prentice-Hall, 1989 [3] M Krstic, I Kanellakopoulos, and P V Kokotovic, _Nonlinear and_\n_Adaptive Control Design_ New York, NY, USA: John Wiley & Sons,\n1995 [4] M A Duarte and K Narendra, “Combined direct and indirect approach to adaptive control,” _IEEE Trans Autom Control_, vol 34,\nno 10, pp 1071–1075, Oct 1989 [5] M Krsti´c, P V Kokotovi´c, and I Kanellakopoulos, “Transientperformance improvement with a new class of adaptive controllers,”\n_Syst Control Lett _, vol 21, no 6, pp 451–461, 1993",
    "451–461, 1993 [6] G Chowdhary and E Chowdhary and E Johnson, “A singular value maximizing data\nrecording algorithm for concurrent learning,” in _Proc Am Control_\n_Conf _, 2011, pp 3547–3552 [7] G Chowdhary, T Yucelen, M Mühlegg, and E N Johnson, “Concurrent learning adaptive control of linear systems with exponentially\nconvergent bounds,” _Int J Adapt Adapt Control Signal Process Control Signal Process _, vol 27,\nno 4, pp 280–301, 2013 [8] S Kersting and M Buss, “Concurrent learning adaptive identification\nof piecewise affine systems,” in _Proc IEEE Conf Decis Control_, Dec 2014, pp 3930–3935 [9] G Chowdhary, M Mühlegg, J How, and F Holzapfel, “Concurrent\nlearning adaptive model predictive control,” in _Advances in Aerospace_\n_Guidance, Navigation and Control_, Q Chu, B Mulder, D Choukroun,\nE -J van Kampen, C de Visser, and G Looye, Eds Springer Berlin\nHeidelberg, 2013, pp 29–47 [10] H Modares, F L Lewis, and M -B Naghibi-Sistani, “Integral reinforcement learning and experience replay for adaptive optimal control\nof partially-unknown constrained-input continuous-time systems,” _Au-_\n_tomatica_, vol Naghibi-Sistani, “Integral reinforcement learning and experience replay for adaptive optimal control\nof partially-unknown constrained-input continuous-time systems,” _Au-_\n_tomatica_, vol 50, no 1, pp 193–202, 2014 [11] R Kamalapurkar, J Klotz, and W E Dixon, “Concurrent learningbased online approximate feedback Nash equilibrium solution of\n_N_ -player nonzero-sum differential games,” _IEEE/CAA J Autom Sin _,\nvol 1, no 3, pp 239–247, Jul 239–247, Jul 2014, Special Issue on Extensions of\nReinforcement Learning and Adaptive Control [12] B Luo, H -N Wu, T Huang, and D",
    "Huang, and D Liu, “Data-based approximate\npolicy iteration for affine nonlinear continuous-time optimal control\ndesign,” _Automatica_, 2014 Liu, “Data-based approximate\npolicy iteration for affine nonlinear continuous-time optimal control\ndesign,” _Automatica_, 2014 [13] R Kamalapurkar, P Walters, and W E Dixon, “Modelbased reinforcement learning for approximate optimal regulation,”\n_Automatica_, vol 64, pp 94–104, Feb 2016 [14] T Bian and Z -P Jiang, “Value iteration and adaptive dynamic\nprogramming for data-driven adaptive optimal control design,” _Au-_\n_tomatica_, vol 71, pp 348–360, 2016 [15] R Kamalapurkar, J A Rosenfeld, and W E Dixon, “Efficient\nmodel-based reinforcement learning for approximate online optimal\ncontrol,” _Automatica_, vol 74, pp 247–258, Dec 2016 [16] R Kamalapurkar, B Reish, G Chowdhary, and W E E Dixon,\n“Concurrent learning for parameter estimation using dynamic\nstate-derivative estimators,” _IEEE Trans Autom Control_, 2017, to\n\nappear [17] A Parikh, R Kamalapurkar, and W E Dixon, “Integral concurrent\nlearning: Adaptive control with parameter convergence without PE or\nstate derivatives,” 2017, submitted, see arXiv:1512 Dixon, “Integral concurrent\nlearning: Adaptive control with parameter convergence without PE or\nstate derivatives,” 2017, submitted, see arXiv:1512 03464, automatica [18] R [18] R Kamalapurkar, “Online output-feedback parameter and state estimation for second order linear systems,” in _Proc Kamalapurkar, “Online output-feedback parameter and state estimation for second order linear systems,” in _Proc Am Control Conf Control Conf _,\n2017, to appear, see also, arXiv:1609 05879 [19] H T Dinh, R Kamalapurkar, S Bhasin, and W E E Dixon,\n“Dynamic neural network-based robust observers for uncertain\nnonlinear systems,” _Neural Netw Dixon,\n“Dynamic neural network-based robust observers for uncertain\nnonlinear systems,” _Neural Netw _, vol 60, pp 44–52, Dec 2014 [20] B Xian, M S de Queiroz, D M Dawson, and M McIntyre, “A\ndiscontinuous output feedback controller and velocity observer for\nnonlinear mechanical systems,” _Automatica_, vol McIntyre, “A\ndiscontinuous output feedback controller and velocity observer for\nnonlinear mechanical systems,” _Automatica_, vol 40, no 4, pp 695–\n700, 2004 [21] G [21] G Chowdhary, “Concurrent learning for convergence in adaptive\ncontrol without persistency of excitation,” Ph D dissertation, Georgia\nInstitute of Technology, Dec 2010 [22] H K Khalil, _Nonlinear Systems_, 3rd ed Upper Saddle River, NJ:\nPrentice Hall, 2002"
  ]
}